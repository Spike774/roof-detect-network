printer: <experiment_settings.PrintLogSave instance at 0x7f7b4e190bd8>
roofs_only: True
data_augmentation: True
scaler: StandardScaler
display_mistakes: True
non_roofs: 1
test_percent: 0.2
net: MyNeuralNet(X_tensor_type=None,
      batch_iterator_test=<FlipBatchIterator.CropOnlyBatchIterator object at 0x7f7b4e189e50>,
      batch_iterator_train=<FlipBatchIterator.FlipBatchIterator object at 0x7f7b4e189e90>,
      custom_score=None, eval_size=0.2, input_shape=(None, 3, 32, 32),
      layers=[('input', <class 'lasagne.layers.input.InputLayer'>), ('conv1', <class 'lasagne.layers.conv.Conv2DLayer'>), ('pool1', <class 'lasagne.layers.pool.MaxPool2DLayer'>), ('output', <class 'lasagne.layers.dense.DenseLayer'>)],
      loss=None, max_epochs=250, more_params={},
      net_name='conv1_nonroofs1_test20_roofs',
      objective=<class 'lasagne.objectives.Objective'>,
      objective_loss_function=<function categorical_crossentropy at 0x7f7b68d1a8c0>,
      on_epoch_finished=[<experiment_settings.PrintLogSave instance at 0x7f7b4e190bd8>, <nolearn.lasagne.handlers.PrintLog instance at 0x7f7b4e190cb0>],
      on_training_finished=[],
      on_training_started=[<experiment_settings.SaveLayerInfo instance at 0x7f7b4e190c20>, <nolearn.lasagne.handlers.PrintLayerInfo instance at 0x7f7b4e190cf8>],
      output_nonlinearity=<function softmax at 0x7f7b58125938>,
      output_num_units=3, preproc_scaler=None, regression=False,
      update=<function nesterov_momentum at 0x7f7b57fd01b8>,
      update_learning_rate=0.01, update_momentum=0.9,
      use_label_encoder=False, verbose=1,
      y_tensor_type=TensorType(int32, vector))
plot_loss: True
preloaded: False

# Neural Network with 22499 learnable parameters
## Layer information

  #  name    size
---  ------  --------
  0  input   3x32x32
  1  conv1   32x30x30
  2  pool1   32x15x15
  3  output  3 

