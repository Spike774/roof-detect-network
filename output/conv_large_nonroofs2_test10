printer: <experiment_settings.PrintLogSave instance at 0x7f43dd578440>
data_augmentation: True
scaler: StandardScaler
display_mistakes: True
non_roofs: 2
test_percent: 0.1
net: MyNeuralNet(X_tensor_type=None,
      batch_iterator_test=<FlipBatchIterator.CropOnlyBatchIterator object at 0x7f43dd56ddd0>,
      batch_iterator_train=<FlipBatchIterator.FlipBatchIterator object at 0x7f43dd56de10>,
      conv1_filter_size=(3, 3), conv1_num_filters=32,
      conv2_filter_size=(2, 2), conv2_num_filters=64,
      conv3_filter_size=(2, 2), conv3_num_filters=128, custom_score=None,
      eval_size=0.2, hidden4_num_units=500, hidden5_num_units=500,
      input_shape=(None, 3, 32, 32),
      layers=[('input', <class 'lasagne.layers.input.InputLayer'>), ('conv1', <class 'lasagne.layers.conv.Conv2DLayer'>), ('pool1', <class 'lasagne.layers.pool.MaxPool2DLayer'>), ('conv2', <class 'lasagne.layers.conv.Conv2DLayer'>), ('pool2', <class 'lasagne.layers.pool.MaxPool2DLayer'>), ('conv3', <class..., <class 'lasagne.layers.dense.DenseLayer'>), ('output', <class 'lasagne.layers.dense.DenseLayer'>)],
      loss=None, max_epochs=250, more_params={},
      net_name='conv_large_nonroofs2_test10',
      objective=<class 'lasagne.objectives.Objective'>,
      objective_loss_function=<function categorical_crossentropy at 0x7f43f80be8c0>,
      on_epoch_finished=[<experiment_settings.PrintLogSave instance at 0x7f43dd578440>, <nolearn.lasagne.handlers.PrintLog instance at 0x7f43dd578680>],
      on_training_finished=[],
      on_training_started=[<experiment_settings.SaveLayerInfo instance at 0x7f43dd5785f0>, <nolearn.lasagne.handlers.PrintLayerInfo instance at 0x7f43dd5786c8>],
      output_nonlinearity=<function softmax at 0x7f43e754b938>,
      output_num_units=3, pool1_pool_size=(2, 2), pool2_pool_size=(2, 2),
      pool3_pool_size=(2, 2), preproc_scaler=None, regression=False,
      update=<function nesterov_momentum at 0x7f43e72f51b8>,
      update_learning_rate=0.01, update_momentum=0.9,
      use_label_encoder=False, verbose=1,
      y_tensor_type=TensorType(int32, vector))
preloaded: False

# Neural Network with 870551 learnable parameters
## Layer information

  #  name     size
---  -------  --------
  0  input    3x32x32
  1  conv1    32x30x30
  2  pool1    32x15x15
  3  conv2    64x14x14
  4  pool2    64x7x7
  5  conv3    128x6x6
  6  pool3    128x3x3
  7  hidden4  500
  8  hidden5  500
  9  output   3 

1	0.809391995301	0.6631741771	1.22048177274	0.741979166667
2	0.587105677291	0.487260111914	1.20491224899	0.823159722222
3	0.421476604006	0.337303082036	1.24954862986	0.886493055556
4	0.299077216711	0.266719204836	1.12131864255	0.908784722222
5	0.265438564029	0.226566080102	1.17157239032	0.920625
6	0.209001357125	0.188882290552	1.10651642626	0.933784722222
7	0.196785757297	0.162765683403	1.2090125706	0.941354166667
8	0.18833020864	0.146572866367	1.28489135341	0.947604166667
9	0.183614630358	0.141234722207	1.30006720365	0.949166666667
10	0.143743682098	0.126499020755	1.13632248882	0.949826388889
11	0.125589546635	0.1191775392	1.05380214659	0.952291666667
12	0.112584646343	0.105514169578	1.06700973711	0.962083333333
13	0.119482329821	0.107143949126	1.11515704616	0.958958333333
14	0.106746374384	0.089090896802	1.1981737553	0.971215277778
15	0.105040380575	0.0995897226628	1.05473112853	0.963402777778
16	0.103342922479	0.0815231471537	1.26765128786	0.970555555556
17	0.0906519366682	0.0883152378678	1.02645861413	0.971875
18	0.102295285744	0.0887715953402	1.15234254101	0.972118055556
19	0.0896012757207	0.077970337958	1.14917131395	0.974340277778
20	0.0938196592088	0.0820906318118	1.14287900018	0.972777777778
21	0.0986630001047	0.0777413320258	1.26911898129	0.980590277778
22	0.0907805294129	0.0791681208042	1.14668036188	0.974340277778
23	0.0800038326997	0.0696123487213	1.14927644548	0.9796875
24	0.0767154669985	0.0649254724593	1.18159274153	0.9828125
25	0.0692299980733	0.0627253671309	1.10370016534	0.980590277778
26	0.0710659425734	0.062895526462	1.12990456668	0.975243055556
27	0.0768187765954	0.0621009316295	1.23699877892	0.9828125
28	0.0769196383709	0.0635368660943	1.21063003417	0.984375
29	0.0739090426202	0.0475618697855	1.55395578335	0.9828125
30	0.0597194140573	0.0519376171334	1.1498296871	0.9796875
31	0.0759824493648	0.0531059110532	1.43077197732	0.9859375
32	0.0714599393497	0.0802220777437	0.89077647151	0.967673611111
33	0.0686285244265	0.0573247663522	1.19718803571	0.982152777778
34	0.0582159719364	0.0463596842608	1.25574565195	0.984375
35	0.0621239927869	0.0445571462848	1.39425429963	0.9859375
36	0.0555534658034	0.0467384878576	1.18860212108	0.9828125
37	0.051355712452	0.0445634830189	1.15241693362	0.9875
38	0.0548929988776	0.0364576192025	1.50566603301	0.9890625
39	0.0565169063811	0.0426466421717	1.32523695895	0.9859375
40	0.0552470120607	0.0445909756499	1.23897293691	0.9859375
41	0.0533108874541	0.0424335513258	1.25633810483	0.9859375
42	0.0537350763545	0.0501848961257	1.07074200612	0.979930555556
43	0.0631406387383	0.0526214321132	1.19990346524	0.982152777778
44	0.0593577641612	0.0416062957157	1.42665342204	0.982152777778
45	0.0519626471693	0.0497695290701	1.04406547822	0.978368055556
46	0.0439830254788	0.0408014889436	1.07797599101	0.9859375
47	0.0514548431801	0.0375430211982	1.37055680491	0.984375
48	0.0492077387556	0.0397847286573	1.23684992751	0.983715277778
49	0.0512352971125	0.0427615119464	1.19816383426	0.983715277778
50	0.0491376813604	0.0407766601957	1.20504428574	0.9859375
51	0.0518926126757	0.0379406869667	1.36772991805	0.9859375
52	0.0460384916413	0.036685696676	1.25494391037	0.9859375
53	0.0461377714095	0.039423327736	1.17031651205	0.984375
54	0.0455141983454	0.0471520854494	0.965263739909	0.980590277778
55	0.0499215569487	0.0393159030056	1.26975480994	0.9875
56	0.0518189898853	0.0618869086451	0.837317471818	0.983715277778
57	0.0534659683809	0.0408396032292	1.30916963323	0.9859375
58	0.0461766773587	0.0435944050518	1.05923403023	0.985277777778
59	0.0475995142626	0.0419773062121	1.13393446502	0.986840277778
60	0.0464012543284	0.0359603351075	1.29034543726	0.9875
61	0.0484709422805	0.0437234410152	1.10858022962	0.982152777778
62	0.056298638272	0.0337021342672	1.67047694445	0.9890625
63	0.0479656534031	0.0393581663556	1.21869634296	0.9890625
64	0.0468467771799	0.0327469540611	1.43056899559	0.9890625
65	0.0408264388977	0.0406807416064	1.00358148071	0.990625
66	0.0403189363366	0.0289985132013	1.39037943279	0.9890625
67	0.03636255604	0.026448973637	1.37481917216	0.9921875
68	0.0403391423267	0.0354516271527	1.13786433985	0.990625
69	0.039768031887	0.0406132781996	0.979187931877	0.984375
70	0.0407347488659	0.0391938143176	1.03931575875	0.990625
71	0.0425730816749	0.0298478260589	1.42633777049	0.9921875
72	0.0443164671516	0.0328563064073	1.34879638028	0.9890625
73	0.0370924490513	0.0314545698385	1.17923879556	0.990625
74	0.0340212995394	0.0319209004883	1.06580011901	0.9890625
75	0.045736816147	0.036892802831	1.23972191423	0.9890625
76	0.0354522681168	0.0346484831997	1.02319827141	0.9890625
77	0.0357297856756	0.0464929163412	0.768499558371	0.981493055556
78	0.0431164549275	0.037302684036	1.1558539564	0.984375
79	0.0360627961381	0.0404377141181	0.891810947393	0.983715277778
80	0.0398393061189	0.0341937799271	1.16510389328	0.9890625
81	0.0435028359185	0.0599199543453	0.72601583886	0.980590277778
82	0.0397454858698	0.034348621187	1.15712027139	0.984375
83	0.038130491167	0.0301464835497	1.26484042838	0.9875
84	0.0314964089206	0.0315192346605	0.999275815541	0.9890625
85	0.0331618791285	0.031080177841	1.06697842265	0.990625
86	0.0315983364692	0.0291400597739	1.08436072933	0.988402777778
87	0.039487996479	0.0274409336277	1.43901796545	0.9921875
88	0.0341943737904	0.0426837945976	0.801109041798	0.985277777778
89	0.0332959587438	0.0359797406674	0.92540852508	0.988402777778
90	0.0238100068278	0.0268277005398	0.887515752327	0.9921875
91	0.0302415809781	0.0301246561047	1.00388136791	0.990625
92	0.0323079358648	0.0338764207644	0.953699804636	0.9875
93	0.0369269126939	0.0441004397655	0.83733660912	0.983715277778
94	0.0410474832355	0.0309856097483	1.32472730306	0.9875
95	0.0332648535137	0.0248482438599	1.33872050279	0.990625
96	0.0303187191195	0.0260735045392	1.16281718378	0.9890625
97	0.0288693811023	0.0314955535942	0.916617674806	0.986840277778
98	0.0318473504852	0.0381875385413	0.833972329763	0.990625
99	0.0261760918893	0.027828602373	0.940618272468	0.990625
100	0.0329865499185	0.0287076295507	1.14905167841	0.9875
101	0.0274933364635	0.0339486787661	0.809849969506	0.9890625
102	0.0304474493782	0.0307026031487	0.991689506937	0.9890625
103	0.0302014967753	0.0278741698083	1.08349403706	0.990625
104	0.0328840157577	0.0329448607701	0.998153125829	0.990625
105	0.0295615381912	0.034680511697	0.852396252094	0.990625
106	0.0280904488693	0.0291892240943	0.962356819713	0.990625
107	0.0320721786058	0.0305270032371	1.05061667392	0.989965277778
108	0.0271780282452	0.0337051650539	0.806346095671	0.989965277778
109	0.0286590968993	0.0383721018855	0.746873261852	0.985277777778
110	0.0236542262045	0.0233343836437	1.01370692132	0.99375
111	0.023804845068	0.0270302838439	0.880673144441	0.9921875
112	0.0285791820107	0.0279926206115	1.02095414386	0.9890625
113	0.0351815364674	0.0276845832412	1.27079884717	0.9921875
114	0.0492169247062	0.0337258913282	1.4593216893	0.9875
115	0.0305408165239	0.0314870832418	0.969947463517	0.9890625
116	0.0291379639917	0.0288512820227	1.00993654177	0.99375
117	0.0286515077339	0.0280291759304	1.02220300037	0.9890625
118	0.0365112171754	0.0319797601621	1.14169765472	0.9875
119	0.0295801096572	0.0347955923853	0.850110822361	0.986840277778
120	0.0293077203208	0.0334584582638	0.875943538395	0.9890625
121	0.0290416529746	0.030502368975	0.952111391691	0.9921875
122	0.026689774108	0.031138984295	0.857117684224	0.983715277778
123	0.0293476118815	0.0312621074529	0.938759868501	0.990625
124	0.0247881788539	0.0265218112501	0.934633710351	0.9859375
125	0.0244374872959	0.0227187972156	1.07565057534	0.9921875
126	0.0233682533473	0.0245669138316	0.951208340919	0.99375
127	0.0439459807362	0.0397434714159	1.10574087191	0.9859375
128	0.0244077510431	0.0332633009848	0.733774169145	0.9890625
129	0.0222963819496	0.0235310666896	0.947529589022	0.990625
130	0.0315259945083	0.0278928158593	1.1302549971	0.9921875
131	0.0263993166593	0.032414411752	0.81443145911	0.9890625
132	0.0224997746197	0.0291095750725	0.772933804896	0.9921875
133	0.0196980698544	0.0214773968673	0.917153506831	0.9921875
134	0.0281605701869	0.0226198256563	1.2449508062	0.9921875
135	0.0198435687382	0.0296156579803	0.670036395998	0.9921875
136	0.0230462563136	0.0305953913346	0.753259079497	0.991527777778
137	0.0233431352695	0.0218226019695	1.0696769937	0.99375
138	0.0239508303431	0.0277210799303	0.863993408745	0.990625
139	0.0195555949396	0.0202510140483	0.965660035242	0.99375
140	0.0239100233172	0.0233288758919	1.02491107707	0.99375
141	0.028047410299	0.0206545500858	1.35792889133	0.9921875
142	0.0242380756089	0.0233508155837	1.03799696084	0.9921875
143	0.0281517396125	0.0298083465279	0.944424729701	0.9890625
144	0.020225239118	0.0242469566601	0.834135161848	0.9921875
145	0.0239246575969	0.0247019470742	0.96853327088	0.9921875
146	0.0181319591475	0.0252380816594	0.718436503699	0.990625
147	0.0244411750641	0.0270778545245	0.902625983238	0.99375
148	0.0176760762427	0.0221300868916	0.798735058261	0.99375
149	0.0196920265868	0.021311597622	0.92400517953	0.99375
150	0.0215035542877	0.0264435123819	0.813188277607	0.99375
151	0.0194360933514	0.0215784262791	0.900718759561	0.99375
152	0.0142632242178	0.0236642949842	0.602731846747	0.990625
153	0.0227612897143	0.0285972099058	0.795926937951	0.991527777778
154	0.0148174174464	0.048995412991	0.302424585117	0.985277777778
155	0.111599413327	0.0607932541869	1.83572034133	0.983055555556
156	0.0277360077606	0.0370602419121	0.748403311192	0.989965277778
157	0.0229783427506	0.0300040082417	0.765842435635	0.9890625
158	0.0231210511224	0.0274184929272	0.843264842595	0.9921875
159	0.020472511821	0.0319404527881	0.640958722682	0.9890625
160	0.0274586624232	0.0492276931485	0.557788932752	0.979930555556
161	0.0264029354099	0.0250435046399	1.05428276871	0.990625
162	0.0225326952813	0.0313380854843	0.71901952315	0.9890625
163	0.0218146071012	0.0268740707295	0.811734378494	0.985277777778
164	0.0215573944715	0.0348047890184	0.61938012209	0.9875
165	0.0220916674467	0.0502579544357	0.439565591055	0.981493055556
166	0.0261215294998	0.0348891518313	0.748700616915	0.9859375
167	0.0253266395467	0.0354606668959	0.714217801403	0.982152777778
168	0.0171505799061	0.0222520349179	0.770742090304	0.9921875
169	0.0211669825402	0.0313795918163	0.674546140184	0.988402777778
170	0.0169367390351	0.0300954939494	0.562766607637	0.9890625
171	0.0230430538894	0.0240869335836	0.956661993086	0.9921875
172	0.0223455994619	0.0184821961687	1.20903377813	0.99375
173	0.0185290397286	0.0235177218252	0.787875622748	0.990625
174	0.0278807592986	0.023937627522	1.16472525412	0.9921875
175	0.0168295186298	0.02937639104	0.572892654067	0.9875
176	0.0196685179251	0.0206589791216	0.952056624355	0.990625
177	0.0158412260502	0.0209096201404	0.757604678796	0.99375
178	0.0168523902378	0.0321928180011	0.523482915886	0.9875
179	0.0124619712232	0.0227536210611	0.547691780125	0.99375
180	0.0168368061751	0.015794442813	1.0659955767	0.9953125
181	0.0166948132076	0.0239606777201	0.69675880635	0.991527777778
182	0.0158702777363	0.024921874676	0.636801121211	0.9921875
183	0.0198916599621	0.0169147009093	1.17599832648	0.993090277778
184	0.0178956060174	0.0216656996208	0.825987913182	0.9953125
185	0.0188049686088	0.0318736921126	0.589984007577	0.990625
186	0.0155639422162	0.0198110069393	0.785620956262	0.9921875
187	0.0155614134541	0.0240042243687	0.648278120343	0.99375
188	0.0113622030748	0.0208813939313	0.54413048823	0.99375
189	0.0188302777926	0.017048070765	1.10454010029	0.9953125
190	0.0253660077185	0.0229356648278	1.10596348128	0.99375
191	0.0189164067769	0.0203896384705	0.927746061033	0.9890625
192	0.019019802619	0.0196673128202	0.967076834182	0.99375
193	0.0251138508842	0.0278268550596	0.902504103695	0.989965277778
194	0.0211352774678	0.0230795340561	0.91575841247	0.9890625
195	0.0187785134324	0.0232343014361	0.808223715441	0.993090277778
196	0.0225105035586	0.0352221569724	0.639100654062	0.988402777778
197	0.0297780973175	0.0317398215345	0.938193596495	0.9875
198	0.0129808142824	0.0213544966484	0.607872641351	0.990625
199	0.0159209175203	0.02468049866	0.645080868892	0.99375
200	0.0131561386683	0.0226939749558	0.579719449499	0.9921875
201	0.0229882816279	0.035840941613	0.641397256693	0.989965277778
202	0.0118304904961	0.0203845994934	0.580364137148	0.9953125
203	0.0178023534034	0.0284803322125	0.625075342189	0.9875
204	0.014088012997	0.0252026142586	0.558990144928	0.9921875
205	0.0197212134096	0.0262037672616	0.752609852346	0.9921875
206	0.0159163040745	0.0212170578288	0.750165466059	0.9890625
207	0.0120415500394	0.0215977051072	0.557538404178	0.9921875
208	0.0125476150549	0.0201695995428	0.622105313902	0.99375
209	0.0159851571644	0.0219017624896	0.729857114099	0.990625
210	0.0154208420439	0.0278401736727	0.553906100774	0.991527777778
211	0.0136929421516	0.0258530088367	0.52964597808	0.990625
212	0.0113932842243	0.0182534412626	0.624171851236	0.99375
213	0.0187637575958	0.0228941027244	0.819589123962	0.99375
214	0.0142767154732	0.0222107853437	0.6427830107	0.9921875
215	0.0142208640041	0.0171507317137	0.829169521246	0.9921875
216	0.016283187038	0.0173667560495	0.937606712023	0.99375
217	0.0142487295335	0.0222889071008	0.639274481656	0.9921875
218	0.0131556967861	0.0173638455692	0.757648801567	0.9921875
219	0.0127425531967	0.0140154190156	0.909181037145	0.9953125
220	0.0109533427173	0.0190612704127	0.574638651053	0.9953125
221	0.0122795231044	0.015051104178	0.81585529933	0.99375
222	0.0130959484576	0.0208613468588	0.627761407076	0.9921875
223	0.0155392749631	0.0283041456169	0.549010564509	0.9921875
224	0.0112004465955	0.0263837958578	0.424519908198	0.990625
225	0.0224734740156	0.0289207815948	0.777070078203	0.987743055556
226	0.0146599659836	0.0216816610782	0.676145888027	0.991527777778
227	0.0119941986934	0.0174505406399	0.687325335123	0.99375
228	0.0159316091736	0.0214022016079	0.744391136271	0.991527777778
229	0.0152681755437	0.0133542876323	1.14331636132	0.99375
230	0.0154706547471	0.0226202606353	0.683929111008	0.9921875
231	0.0200831550443	0.0390633648003	0.514117387148	0.9890625
232	0.0160959070472	0.0183411249491	0.877585594768	0.99375
233	0.0156942045995	0.0181364652381	0.865339766788	0.99375
234	0.0105047816225	0.0186836554555	0.562244451973	0.99375
235	0.0136374933322	0.0198799401447	0.685992675677	0.990625
236	0.00786954702607	0.011951784267	0.65844118755	0.9953125
237	0.0187527117917	0.0195155457725	0.960911470799	0.9953125
238	0.0158161322149	0.0225236073721	0.702202447133	0.988402777778
239	0.0100869252888	0.0165353975001	0.610020127347	0.9921875
240	0.00834001949253	0.0193365780149	0.431307932877	0.99375
241	0.00948114708551	0.0310147581005	0.305697921447	0.989965277778
242	0.0125263250053	0.0155227963733	0.80696317236	0.99375
243	0.0164152023573	0.0226476223518	0.724809081602	0.988402777778
244	0.0131413045517	0.024864834007	0.528509643298	0.99375
245	0.0185893849752	0.0172460539168	1.07789208273	0.991527777778
246	0.0171232926342	0.020188816261	0.84815733686	0.990625
247	0.00870204558388	0.0132314591602	0.657678452432	0.9953125
248	0.0116294147872	0.0164658705349	0.706273911394	0.9953125
249	0.0123813521786	0.0243488262725	0.508498932969	0.990625
250	0.0138272285981	0.0185903529366	0.743785158102	0.9921875


Confusion Matrix
[[241   0   0]
 [  0  59   1]
 [  0   2  32]]


Report
             precision    recall  f1-score   support

          0       1.00      1.00      1.00       241
          1       0.97      0.98      0.98        60
          2       0.97      0.94      0.96        34

avg / total       0.99      0.99      0.99       335
