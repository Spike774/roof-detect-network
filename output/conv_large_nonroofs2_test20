printer: <experiment_settings.PrintLogSave instance at 0x7f94f2062440>
data_augmentation: True
scaler: StandardScaler
display_mistakes: True
non_roofs: 2
test_percent: 0.2
net: MyNeuralNet(X_tensor_type=None,
      batch_iterator_test=<FlipBatchIterator.CropOnlyBatchIterator object at 0x7f94f2057dd0>,
      batch_iterator_train=<FlipBatchIterator.FlipBatchIterator object at 0x7f94f2057e10>,
      conv1_filter_size=(3, 3), conv1_num_filters=32,
      conv2_filter_size=(2, 2), conv2_num_filters=64,
      conv3_filter_size=(2, 2), conv3_num_filters=128, custom_score=None,
      eval_size=0.2, hidden4_num_units=500, hidden5_num_units=500,
      input_shape=(None, 3, 32, 32),
      layers=[('input', <class 'lasagne.layers.input.InputLayer'>), ('conv1', <class 'lasagne.layers.conv.Conv2DLayer'>), ('pool1', <class 'lasagne.layers.pool.MaxPool2DLayer'>), ('conv2', <class 'lasagne.layers.conv.Conv2DLayer'>), ('pool2', <class 'lasagne.layers.pool.MaxPool2DLayer'>), ('conv3', <class..., <class 'lasagne.layers.dense.DenseLayer'>), ('output', <class 'lasagne.layers.dense.DenseLayer'>)],
      loss=None, max_epochs=250, more_params={},
      net_name='conv_large_nonroofs2_test20',
      objective=<class 'lasagne.objectives.Objective'>,
      objective_loss_function=<function categorical_crossentropy at 0x7f950cba88c0>,
      on_epoch_finished=[<experiment_settings.PrintLogSave instance at 0x7f94f2062440>, <nolearn.lasagne.handlers.PrintLog instance at 0x7f94f2062680>],
      on_training_finished=[],
      on_training_started=[<experiment_settings.SaveLayerInfo instance at 0x7f94f20625f0>, <nolearn.lasagne.handlers.PrintLayerInfo instance at 0x7f94f20626c8>],
      output_nonlinearity=<function softmax at 0x7f94fc035938>,
      output_num_units=3, pool1_pool_size=(2, 2), pool2_pool_size=(2, 2),
      pool3_pool_size=(2, 2), preproc_scaler=None, regression=False,
      update=<function nesterov_momentum at 0x7f94fbddf1b8>,
      update_learning_rate=0.01, update_momentum=0.9,
      use_label_encoder=False, verbose=1,
      y_tensor_type=TensorType(int32, vector))
preloaded: False

# Neural Network with 870551 learnable parameters
## Layer information

  #  name     size
---  -------  --------
  0  input    3x32x32
  1  conv1    32x30x30
  2  pool1    32x15x15
  3  conv2    64x14x14
  4  pool2    64x7x7
  5  conv3    128x6x6
  6  pool3    128x3x3
  7  hidden4  500
  8  hidden5  500
  9  output   3 

1	0.841649038509	0.693531482991	1.21357005291	0.730208333333
2	0.636438656467	0.569279819849	1.11797157439	0.756770833333
3	0.488694273001	0.457159364488	1.06898012151	0.8703125
4	0.360035733229	0.326798862064	1.10170436627	0.881770833333
5	0.261285105057	0.237143518956	1.10180158499	0.9125
6	0.219471037923	0.224421295726	0.977942120922	0.9171875
7	0.180858965072	0.179805743013	1.00585755516	0.940104166667
8	0.161614164754	0.168328497594	0.960111728341	0.940104166667
9	0.150142690224	0.149130047543	1.00679033299	0.949479166667
10	0.254856013683	0.177991121715	1.43184677543	0.931770833333
11	0.14384290029	0.169172581391	0.850273130004	0.943229166667
12	0.126390479667	0.143328382317	0.881824504147	0.949479166667
13	0.114319938141	0.124088486334	0.921277561829	0.955729166667
14	0.0954068487967	0.109415419431	0.87196895367	0.960416666667
15	0.0977284227755	0.103672527455	0.942664611103	0.960416666667
16	0.0992924209536	0.0919122659389	1.08029564867	0.965104166667
17	0.0927124249716	0.0991361240834	0.935203245324	0.963541666667
18	0.0908714089459	0.0759328556751	1.19673372136	0.971875
19	0.0854176431558	0.0768299161758	1.11177582129	0.966666666667
20	0.0851117014539	0.0734450813327	1.15884821569	0.966666666667
21	0.0834927141701	0.0740999764873	1.12675763378	0.98125
22	0.0858789866121	0.0681426736269	1.2602820236	0.978125
23	0.0759854519084	0.0690368199974	1.10065110055	0.969791666667
24	0.0789818577404	0.0851087667681	0.928010835307	0.9796875
25	0.0753286590835	0.0717244270517	1.05025110942	0.984375
26	0.0705148662435	0.0712954448485	0.98905149401	0.9828125
27	0.0848268830758	0.073774099561	1.14981929404	0.971354166667
28	0.0664610169624	0.0665314017937	0.998942081042	0.9828125
29	0.0721176871401	0.0580049398361	1.2433025074	0.9828125
30	0.0664108576848	0.0604929773063	1.09782756019	0.9796875
31	0.0643008838281	0.0687079641265	0.935857795316	0.972916666667
32	0.0681788821034	0.0627227573943	1.08698795997	0.971354166667
33	0.0717107435076	0.0636032596366	1.1274696284	0.9875
34	0.0558337911225	0.0529063665513	1.05533217951	0.984375
35	0.0605533876666	0.0613448251819	0.987098544777	0.9828125
36	0.0673900594724	0.0482178734673	1.39761575172	0.990625
37	0.0562127371198	0.0513737252581	1.09419234905	0.9890625
38	0.0659539889722	0.0527846025725	1.24949295359	0.984375
39	0.0651005270189	0.0481735487339	1.35137495015	0.9875
40	0.0637340402214	0.045091970289	1.41342327277	0.984375
41	0.0597282631906	0.0488401310748	1.2229341297	0.984375
42	0.0628030936495	0.045075792875	1.39327762517	0.9875
43	0.0510976866576	0.0425570619984	1.20068642566	0.9875
44	0.0491559600319	0.050711711556	0.969321652211	0.9859375
45	0.0620040141949	0.0511432935235	1.21235864809	0.9859375
46	0.0615540192495	0.0417290773145	1.47508699475	0.9875
47	0.0540853772089	0.0532839428702	1.01504082272	0.974479166667
48	0.05718601025	0.060088838539	0.951691056782	0.9828125
49	0.0604342639536	0.0408800315377	1.47833212648	0.9875
50	0.0499508851268	0.0478163252702	1.04464081764	0.979166666667
51	0.0495992034278	0.0485425053559	1.02176851121	0.9875
52	0.0588013890626	0.0917998909931	0.640538767818	0.971354166667
53	0.0591967944627	0.0564802656321	1.04809695564	0.9828125
54	0.0586162330143	0.0444042163793	1.32006007073	0.9875
55	0.0441630382496	0.0449616345955	0.982238271516	0.977604166667
56	0.0460660067425	0.0512267965059	0.899256051218	0.984375
57	0.0387264840003	0.0382242210361	1.01313991366	0.990625
58	0.0441582542023	0.0462966000098	0.953812033561	0.9890625
59	0.0526370058099	0.0447025505888	1.17749446322	0.9890625
60	0.0550817988981	0.0584742528309	0.941983800243	0.984375
61	0.0516171855541	0.0341605068377	1.51101931243	0.9890625
62	0.048447135177	0.0479868212417	1.00959250735	0.9828125
63	0.0489365687056	0.0358488245275	1.36508154314	0.9890625
64	0.0463710332992	0.035920792675	1.290924555	0.9875
65	0.0432662843413	0.0340798811394	1.26955502469	0.9875
66	0.0419451172953	0.0385108409434	1.08917687248	0.9875
67	0.0367874873842	0.0278793768523	1.31952330137	0.9921875
68	0.0396255515369	0.0347811394778	1.13928273	0.9890625
69	0.0320279478632	0.0539888553707	0.593232578155	0.984375
70	0.0450814777037	0.0312571781515	1.4422759945	0.990625
71	0.0383513690226	0.0288089983927	1.33122882302	0.9921875
72	0.0417476742102	0.0282146766859	1.47964389863	0.990625
73	0.0403464644698	0.0311266708772	1.29620236706	0.9890625
74	0.0511179304863	0.0403922492295	1.26553810351	0.9859375
75	0.0436406656449	0.0378195712065	1.15391751553	0.9875
76	0.0471732218521	0.0383787989231	1.22914794563	0.9875
77	0.0435081007541	0.0340596120235	1.27741034525	0.990625
78	0.0414716872481	0.0374789042271	1.1065341451	0.9890625
79	0.0349741839639	0.0348462756305	1.00367064574	0.990625
80	0.0328401829857	0.0391267270098	0.839328650656	0.9875
81	0.0340864438447	0.0362458099582	0.94042439344	0.990625
82	0.0373547951297	0.0291974126529	1.27938716946	0.990625
83	0.0379289064797	0.0352234123806	1.07680953991	0.9890625
84	0.0324462259775	0.0464029545499	0.699227587816	0.9828125
85	0.044350695861	0.0573343395428	0.773545072894	0.983854166667
86	0.0359947507931	0.0337384215884	1.0668771418	0.9890625
87	0.0403160438991	0.0359803799705	1.12050078215	0.9921875
88	0.0391384816658	0.0764031932423	0.512262380732	0.977604166667
89	0.043132745401	0.0628915642139	0.6858272002	0.976041666667
90	0.0375528616896	0.0404803178081	0.927681987766	0.979166666667
91	0.0371195632481	0.0295273344699	1.25712543697	0.9921875
92	0.0314994531762	0.0305394633281	1.03143440465	0.99375
93	0.031783092298	0.0291764066815	1.08934224303	0.9890625
94	0.0246185306449	0.0364330756171	0.67571925312	0.984375
95	0.0235924536659	0.035103604983	0.67208065033	0.984375
96	0.0390525790887	0.0407792468859	0.957658173481	0.9875
97	0.026247041482	0.0523028234855	0.501828385791	0.971354166667
98	0.0354696711321	0.0270908505149	1.30928599354	0.990625
99	0.0248466488034	0.0713296489982	0.348335497964	0.979166666667
100	0.0341909420012	0.0302783764942	1.12921979181	0.9890625
101	0.115605210051	0.0909299600652	1.271365455	0.976041666667
102	0.0368864685844	0.0560995501778	0.657518081117	0.974479166667
103	0.0354322862996	0.0473991450852	0.747530071184	0.980729166667
104	0.031253240819	0.0426304818628	0.733119576729	0.982291666667
105	0.0428722223712	0.0387611942243	1.10606040988	0.990625
106	0.0349307909641	0.0591643965497	0.590402218246	0.977604166667
107	0.031406933756	0.031055594156	1.01131324676	0.99375
108	0.0265255608996	0.0297178452576	0.892580221401	0.9890625
109	0.0317981178779	0.0274673827171	1.15766828625	0.990625
110	0.0329326256421	0.0463349513217	0.710751273126	0.979166666667
111	0.023973043481	0.0295189417538	0.812124082255	0.990625
112	0.0260639130575	0.0391769189275	0.66528746443	0.9890625
113	0.0242715295268	0.0398331205171	0.609330356541	0.9859375
114	0.0347752871228	0.0354170082053	0.981880991224	0.9875
115	0.0419677220242	0.0634381957439	0.661552894626	0.977604166667
116	0.0290999733383	0.0278891166495	1.04341681753	0.9890625
117	0.0225396361759	0.0298330064109	0.755526810321	0.990625
118	0.0215742221486	0.0437607645906	0.493003775196	0.979166666667
119	0.0263887320888	0.0279529437041	0.944041256198	0.9921875
120	0.024026464169	0.0306478719897	0.783952118343	0.9875
121	0.0296026659529	0.0269036699778	1.10032073607	0.990625
122	0.0222162635791	0.0295592787735	0.751583411401	0.990625
123	0.0212654300407	0.0352401897929	0.603442551405	0.990625
124	0.0305438011794	0.0263301130078	1.16003304545	0.990625
125	0.0266896486296	0.0424753460849	0.628356236963	0.9890625
126	0.0180220464662	0.0293844432828	0.613319309565	0.990625
127	0.0255670765699	0.0299504976644	0.85364446549	0.9890625
128	0.027055017288	0.0460479849466	0.587539657151	0.979166666667
129	0.0268777824493	0.0652647126024	0.41182717854	0.979166666667
130	0.0330121603881	0.0309398359277	1.06697916774	0.9875
131	0.0228002629332	0.029072084167	0.78426654251	0.9921875
132	0.0183859472621	0.0256327206466	0.717284267855	0.99375
133	0.02738717364	0.0478559025319	0.572284131968	0.980729166667
134	0.0293009016157	0.0372725650291	0.786125172571	0.980729166667
135	0.0186533150159	0.0353291976247	0.527985809756	0.9890625
136	0.0186996476194	0.0345120157352	0.541830061821	0.990625
137	0.0247420100712	0.0342922491819	0.721504440842	0.9890625
138	0.0288176638506	0.0492044181575	0.585672281672	0.977604166667
139	0.0247948946138	0.0298313590454	0.831168790401	0.990625
140	0.0268382649412	0.0255941581137	1.04860901546	0.9953125
141	0.0199719046982	0.0262658830977	0.760374384668	0.9921875
142	0.0186822051698	0.0286865538569	0.651253031752	0.990625
143	0.021219762501	0.0280601212985	0.75622490278	0.9890625
144	0.0210592203541	0.0306619117456	0.686820199891	0.9890625
145	0.0191423872195	0.0574750162865	0.333055794609	0.980729166667
146	0.0217834962701	0.0445821947519	0.488614263863	0.979166666667
147	0.0209603892592	0.0283640263368	0.73897792261	0.990625
148	0.0250000275461	0.039933335159	0.626044066856	0.9921875
149	0.0284210868028	0.0394840823003	0.719811254234	0.982291666667
150	0.0219341935787	0.0333913540222	0.656882424238	0.982291666667
151	0.0286470339769	0.0411195752733	0.696676310164	0.9875
152	0.0281672904787	0.0313133458315	0.899529888316	0.9921875
153	0.0181626805667	0.0279191983759	0.65054448635	0.9921875
154	0.0261955395375	0.0358532804318	0.730631596944	0.990625
155	0.0228095164355	0.106892909399	0.2133866181	0.969791666667
156	0.0212953490282	0.0316121892757	0.673643601285	0.99375
157	0.0160911968947	0.0333670205918	0.482248537906	0.9890625
158	0.0197755728853	0.0370837979396	0.533267194411	0.980729166667
159	0.0139350398061	0.023932823758	0.582256400123	0.99375
160	0.0205911465959	0.0243941076399	0.844103293298	0.990625
161	0.0162442872357	0.0294154306674	0.552236933716	0.990625
162	0.0239602772448	0.0273183631445	0.8770758745	0.990625
163	0.0250665690391	0.0308085668806	0.813623338477	0.9890625
164	0.0186768221792	0.0448381847841	0.416538320389	0.979166666667
165	0.0235960037694	0.0394558041315	0.598036316553	0.980729166667
166	0.0173847378934	0.0354391314777	0.490552030158	0.9875
167	0.0142054802509	0.031318918007	0.453575064367	0.990625
168	0.0155393159031	0.026424135396	0.588072823205	0.9890625
169	0.0181356552913	0.0253366309725	0.715787955826	0.99375
170	0.0192289218075	0.0224747652699	0.855578315351	0.990625
171	0.0229353044635	0.0335536492708	0.683541282751	0.9890625
172	0.0166918117416	0.0305712421828	0.545997170863	0.9921875
173	0.0209685333449	0.0571789841902	0.366717486186	0.980729166667
174	0.0346792689166	0.111456209014	0.311147034546	0.972916666667
175	0.0197761550667	0.0223557425993	0.884611861081	0.9921875
176	0.018433988599	0.0212288994785	0.868344052296	0.990625
177	0.0149425529432	0.0269355696378	0.554751696144	0.990625
178	0.0204185684745	0.0290903390584	0.701902044988	0.990625
179	0.0225935197738	0.0308302128402	0.732836970374	0.9890625
180	0.0163729697344	0.0253421547674	0.64607646369	0.990625
181	0.0178335582324	0.0269061750343	0.662805404693	0.9890625
182	0.0166421315506	0.0307201631939	0.541733175231	0.984375
183	0.017685955392	0.0300236402345	0.589067656481	0.99375
184	0.0142666566163	0.0344431554123	0.414208757748	0.9890625
185	0.016720386163	0.0260028395441	0.643021549036	0.990625
186	0.0208431562852	0.0353748749723	0.589207913853	0.9890625
187	0.0143360969539	0.0283898421897	0.504972759556	0.9921875
188	0.0175538095706	0.0322433004493	0.544417268892	0.990625
189	0.0225332775927	0.0365770386331	0.616049807059	0.9859375
190	0.0144036227214	0.0364739539795	0.394901598261	0.9859375
191	0.0199727807465	0.0413632177317	0.48286332258	0.980729166667
192	0.0169112044439	0.0273834591527	0.617570057515	0.990625
193	0.0157193041991	0.0304375556034	0.516444369052	0.9921875
194	0.0142835472765	0.0336627874981	0.424312670997	0.990625
195	0.0151226833441	0.030919945988	0.489091518787	0.9921875
196	0.0213187164248	0.0314173668152	0.678564710727	0.990625
197	0.0134327818617	0.0359085196757	0.374083420399	0.9890625
198	0.0126483196034	0.0343460407902	0.368261357419	0.9890625
199	0.0189627423521	0.0437762940256	0.433173770741	0.9921875
200	0.0173207580983	0.0330896005691	0.523450201889	0.9921875
201	0.0145405605342	0.0269871321695	0.538796061876	0.990625
202	0.0166734415542	0.0304471109062	0.547619825262	0.99375
203	0.0155252508302	0.0295350181546	0.525655706354	0.990625
204	0.0197352379045	0.0292908754945	0.673767430003	0.9921875
205	0.0182653467261	0.0322797572055	0.565845232658	0.990625
206	0.0148368286148	0.029966566224	0.495112736769	0.990625
207	0.0115480557603	0.0278531747028	0.414604650404	0.990625
208	0.0137907803583	0.0305423151339	0.451530288319	0.990625
209	0.0290004785306	0.0279452126534	1.03776195552	0.990625
210	0.021941849351	0.0377465086494	0.581294804106	0.982291666667
211	0.0176762883007	0.0328616234788	0.537900639999	0.990625
212	0.0149169037431	0.0336623387355	0.443133314661	0.990625
213	0.0187020799269	0.0561824073216	0.332881427095	0.977604166667
214	0.0132801929561	0.0303482201362	0.437593799454	0.9921875
215	0.0122161763103	0.0688821037244	0.177349059476	0.979166666667
216	0.0182853324543	0.0360967971589	0.506563847584	0.990625
217	0.0153882371673	0.0341135370837	0.451088877988	0.983854166667
218	0.00805290118906	0.0307577128024	0.261817295739	0.9890625
219	0.0183379732616	0.0297624753732	0.616144088545	0.9921875
220	0.00938313932955	0.0241713388707	0.388192784013	0.990625
221	0.0143598498074	0.0245092899374	0.585894158668	0.99375
222	0.0187375010755	0.025457713779	0.736024500791	0.9921875
223	0.0112304268113	0.0269378645509	0.416901153767	0.990625
224	0.0138356221859	0.0292256144398	0.473407401388	0.9921875
225	0.00799003514503	0.0448261992671	0.178244760333	0.982291666667
226	0.0198559319853	0.026859971003	0.739238772191	0.990625
227	0.0176342899384	0.0797789130872	0.22103948595	0.977604166667
228	0.0129385934264	0.0265135307391	0.48799963889	0.990625
229	0.011463912268	0.0293083858185	0.391147855735	0.990625
230	0.0120357132731	0.036715513576	0.32781002091	0.990625
231	0.0165158176929	0.0378845496193	0.435951274567	0.990625
232	0.0134234321901	0.024190247273	0.554910912593	0.99375
233	0.0138530690758	0.0300109342798	0.46160072681	0.9921875
234	0.0108436190203	0.0396438404416	0.273525947525	0.9890625
235	0.0101166066574	0.032036923581	0.315779592001	0.9921875
236	0.0136117868896	0.0195021505081	0.697963380192	0.9953125
237	0.00952845240109	0.0290234279273	0.328302102183	0.990625
238	0.0084202307045	0.0315517313558	0.266870638874	0.990625
239	0.0147267431601	0.0273791004667	0.537882651695	0.990625
240	0.00668083042896	0.025633581599	0.26062805165	0.9921875
241	0.0121356003311	0.0201201971487	0.603155140153	0.990625
242	0.015693503573	0.0435660664716	0.360223101234	0.9875
243	0.0215245552478	0.0511639106689	0.420698006983	0.980729166667
244	0.0137379072739	0.0236225050406	0.581560137263	0.9890625
245	0.0118348632937	0.0292766091885	0.404242964665	0.990625
246	0.00694384414563	0.0238667089919	0.290942674501	0.990625
247	0.00687696259133	0.0242111393902	0.284041262185	0.9921875
248	0.0113215322683	0.026023768173	0.43504584705	0.990625
249	0.00955184130575	0.0215440356883	0.443363603921	0.99375
250	0.0169001972178	0.0739262984791	0.228608730121	0.974479166667


Confusion Matrix
[[459   4   1]
 [  0 140   5]
 [  0   1  59]]


Report
             precision    recall  f1-score   support

          0       1.00      0.99      0.99       464
          1       0.97      0.97      0.97       145
          2       0.91      0.98      0.94        60

avg / total       0.98      0.98      0.98       669
