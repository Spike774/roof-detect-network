printer: <experiment_settings.PrintLogSave instance at 0x7f1ec97f4440>
data_augmentation: True
scaler: StandardScaler
display_mistakes: True
non_roofs: 3
test_percent: 0.2
net: MyNeuralNet(X_tensor_type=None,
      batch_iterator_test=<FlipBatchIterator.CropOnlyBatchIterator object at 0x7f1ec97e9e10>,
      batch_iterator_train=<FlipBatchIterator.FlipBatchIterator object at 0x7f1ec97e9e50>,
      conv1_filter_size=(3, 3), conv1_num_filters=32,
      conv2_filter_size=(2, 2), conv2_num_filters=64,
      conv3_filter_size=(2, 2), conv3_num_filters=128, custom_score=None,
      eval_size=0.2, hidden4_num_units=500, hidden5_num_units=500,
      input_shape=(None, 3, 32, 32),
      layers=[('input', <class 'lasagne.layers.input.InputLayer'>), ('conv1', <class 'lasagne.layers.conv.Conv2DLayer'>), ('pool1', <class 'lasagne.layers.pool.MaxPool2DLayer'>), ('conv2', <class 'lasagne.layers.conv.Conv2DLayer'>), ('pool2', <class 'lasagne.layers.pool.MaxPool2DLayer'>), ('conv3', <class..., <class 'lasagne.layers.dense.DenseLayer'>), ('output', <class 'lasagne.layers.dense.DenseLayer'>)],
      loss=None, max_epochs=250, more_params={},
      net_name='conv_large_nonroofs3_test20',
      objective=<class 'lasagne.objectives.Objective'>,
      objective_loss_function=<function categorical_crossentropy at 0x7f1ee433a8c0>,
      on_epoch_finished=[<experiment_settings.PrintLogSave instance at 0x7f1ec97f4440>, <nolearn.lasagne.handlers.PrintLog instance at 0x7f1ec97f4680>],
      on_training_finished=[],
      on_training_started=[<experiment_settings.SaveLayerInfo instance at 0x7f1ec97f45f0>, <nolearn.lasagne.handlers.PrintLayerInfo instance at 0x7f1ec97f46c8>],
      output_nonlinearity=<function softmax at 0x7f1ed37c7938>,
      output_num_units=3, pool1_pool_size=(2, 2), pool2_pool_size=(2, 2),
      pool3_pool_size=(2, 2), preproc_scaler=None, regression=False,
      update=<function nesterov_momentum at 0x7f1ed35711b8>,
      update_learning_rate=0.01, update_momentum=0.9,
      use_label_encoder=False, verbose=1,
      y_tensor_type=TensorType(int32, vector))
preloaded: False

# Neural Network with 870551 learnable parameters
## Layer information

  #  name     size
---  -------  --------
  0  input    3x32x32
  1  conv1    32x30x30
  2  pool1    32x15x15
  3  conv2    64x14x14
  4  pool2    64x7x7
  5  conv3    128x6x6
  6  pool3    128x3x3
  7  hidden4  500
  8  hidden5  500
  9  output   3 

1	0.704987833409	0.590317261792	1.19425244532	0.796452702703
2	0.50553590472	0.446831818394	1.13137848271	0.830201295045
3	0.394072006801	0.360579015849	1.09288668913	0.843820382883
4	0.331704073529	0.274543914305	1.20820042348	0.884079391892
5	0.282299452289	0.211242555212	1.33637586426	0.924092060811
6	0.20952899081	0.190460956878	1.10011518499	0.92138231982
7	0.235668974253	0.167609563155	1.40605923562	0.941863738739
8	0.164938971026	0.133018200305	1.23997295594	0.951928490991
9	0.151229908982	0.119812614714	1.26222025404	0.955482826577
10	0.137607464848	0.113372329495	1.21376587621	0.955482826577
11	0.127553390825	0.105780180174	1.20583450146	0.964245495495
12	0.123875130297	0.0946119005202	1.30929755788	0.965899493243
13	0.17977059419	0.117573854848	1.52900144699	0.958438907658
14	0.123266933044	0.109967531152	1.12093935139	0.964245495495
15	0.10318312833	0.0972957983468	1.06050960147	0.96069115991
16	0.0975778460034	0.0838305888469	1.16398855532	0.965899493243
17	0.0971444911546	0.0677449989772	1.43397287802	0.974662162162
18	0.0746129703903	0.0619392758024	1.20461483322	0.983424831081
19	0.0806327637183	0.0727617817933	1.10817467262	0.96850365991
20	0.143716973382	0.0735564583772	1.95383215223	0.974310247748
21	0.0753498027665	0.0625844558594	1.20396992723	0.976914414414
22	0.0712791053114	0.060759445375	1.17313620741	0.975964245495
23	0.0760975164972	0.0532678782519	1.42858170805	0.983424831081
24	0.116249271091	0.143337032014	0.811020498035	0.947177646396
25	0.0859339831017	0.0593607550478	1.44765650357	0.978216497748
26	0.0720698995225	0.0622864274063	1.15707229526	0.979518581081
27	0.0702686639324	0.0592918239933	1.18513243816	0.975964245495
28	0.0632261653636	0.0504668962711	1.25282452529	0.981172578829
29	0.0634400797884	0.063967955045	0.991747817228	0.969805743243
30	0.0581203964124	0.0509763328902	1.1401447126	0.973711993243
31	0.0483941646552	0.0525224125429	0.921400261569	0.966955236486
32	0.0666317994702	0.0481076603856	1.38505591285	0.979870495495
33	0.0639535907724	0.0606371046473	1.05469400534	0.97631615991
34	0.0576672070682	0.0623695386134	0.92460531776	0.97240990991
35	0.0623380870976	0.0685852990648	0.908913250327	0.972057995495
36	0.0564507191196	0.0471311222779	1.19773763898	0.97631615991
37	0.0527646023588	0.0475612701017	1.10940271877	0.97631615991
38	0.0652616178435	0.0573425325711	1.13810142171	0.980820664414
39	0.10317218735	0.0582886145385	1.77002298248	0.977266328829
40	0.0526457989719	0.0540673069927	0.973708547737	0.980820664414
41	0.0593933154098	0.0460602950822	1.28946884304	0.983424831081
42	0.0518924255242	0.0485515802089	1.06881022823	0.977618243243
43	0.0488753935119	0.0450950714747	1.08383004868	0.979870495495
44	0.0535250959389	0.0401025466947	1.33470565713	0.983424831081
45	0.0559784883302	0.0405066881953	1.38195667985	0.987331081081
46	0.0516483009255	0.0503285561867	1.02622258294	0.979870495495
47	0.0487035449762	0.0540303946016	0.901410129158	0.975964245495
48	0.0502728443538	0.049460517915	1.01642373499	0.977266328829
49	0.0404694536178	0.040971685209	0.987741983552	0.984726914414
50	0.0492075551364	0.0357708816932	1.37563159775	0.983776745495
51	0.044152629041	0.037470936892	1.17831665561	0.986028997748
52	0.0599697340031	0.0345944890158	1.73350541399	0.985078828829
53	0.0532728437579	0.0528063160573	1.00883469508	0.978568412162
54	0.0413260384628	0.0491846503293	0.84022226825	0.981172578829
55	0.0449406188696	0.0353156119405	1.27254254989	0.986028997748
56	0.0391068420504	0.0427346434449	0.915108654197	0.982474662162
57	0.0363723585124	0.0317883153827	1.14420528658	0.988633164414
58	0.0396170128278	0.0352269347773	1.12462276602	0.98412865991
59	0.0391845865292	0.0328152565432	1.19409660801	0.988633164414
60	0.0519193946091	0.0300306740536	1.72887876298	0.991237331081
61	0.037417317307	0.0412858061061	0.906299787651	0.986028997748
62	0.0449670149007	0.0358198264793	1.25536663129	0.985078828829
63	0.0407179139611	0.0264983649166	1.53661986652	0.991237331081
64	0.042108112467	0.0477149761475	0.882492581299	0.984726914414
65	0.0446176525725	0.0336154598894	1.32729561693	0.987331081081
66	0.0525832734278	0.0338717030009	1.55242484933	0.989935247748
67	0.0361072938943	0.0253055917283	1.42685040848	0.992539414414
68	0.0372674820184	0.0289222969719	1.28853811489	0.992539414414
69	0.0372291595923	0.0298444786107	1.24743876674	0.992539414414
70	0.0352947576697	0.0617829513747	0.571270178656	0.978920326577
71	0.0357015991475	0.0342120543465	1.04353859566	0.989935247748
72	0.0335550747276	0.0293278992302	1.1441349571	0.987682995495
73	0.0438296151909	0.0449053957155	0.976043401746	0.988633164414
74	0.0433927420926	0.0386881459112	1.12160304069	0.986028997748
75	0.0386685917859	0.0320481650228	1.20657740493	0.988633164414
76	0.0432285612528	0.0308240877935	1.40242791749	0.986028997748
77	0.025352063576	0.0306500257559	0.827146566788	0.987682995495
78	0.0290714336834	0.0320465739277	0.90716198708	0.991237331081
79	0.030935935794	0.0314802079782	0.982710654754	0.984832488739
80	0.0370667055391	0.0283398626588	1.30793525662	0.989935247748
81	0.0410440889658	0.0347903841914	1.1797538291	0.988633164414
82	0.0363639203743	0.0272649719507	1.33372300695	0.993841497748
83	0.0318721304335	0.0292828698054	1.08842236589	0.985430743243
84	0.0357030101432	0.0323386293907	1.10403597233	0.989935247748
85	0.027255696235	0.0275448183614	0.98950357477	0.990287162162
86	0.0287742772624	0.0432005713088	0.666062424424	0.982474662162
87	0.0343879475578	0.0312401765994	1.10076034457	0.987331081081
88	0.0366008294591	0.0259415798046	1.41089439173	0.992539414414
89	0.0294283515171	0.0311937070242	0.943406677964	0.988633164414
90	0.0278523801577	0.0345210571618	0.806822920492	0.991237331081
91	0.041483629819	0.0278098546668	1.49168811977	0.985430743243
92	0.0344768001926	0.0244427707936	1.41051112756	0.993841497748
93	0.0301491467352	0.033712224758	0.89430902148	0.986028997748
94	0.0312098780719	0.0273131896675	1.14266691118	0.990287162162
95	0.0331861569483	0.0307132673032	1.08051535581	0.989935247748
96	0.0250187834985	0.0298816853999	0.837261458435	0.988985078829
97	0.0298405202616	0.0324581254005	0.919354395653	0.989935247748
98	0.0314358421934	0.028993612817	1.08423335829	0.988633164414
99	0.0421992238576	0.0311937468464	1.35281035861	0.986028997748
100	0.0256158014623	0.0314842832792	0.813605989859	0.989935247748
101	0.03006470482	0.0273969259628	1.0973751165	0.989935247748
102	0.0263063343755	0.0255985038701	1.02765124513	0.992539414414
103	0.0270040923918	0.0313852234395	0.860407842685	0.987682995495
104	0.0296269361315	0.0222352404059	1.33243156317	0.992891328829
105	0.0245485000057	0.0230344712849	1.06572882451	0.990287162162
106	0.035356825448	0.0330520422854	1.06973194402	0.987331081081
107	0.0377575715192	0.0560534078013	0.673599929072	0.977266328829
108	0.0349346077503	0.0243298252711	1.43587581748	0.992539414414
109	0.0347008973972	0.0394147205667	0.880404501117	0.988633164414
110	0.0301817143672	0.0354276044194	0.85192648111	0.989935247748
111	0.0239224291695	0.0416119586345	0.574893130592	0.984726914414
112	0.0280024334878	0.0319271016602	0.877074085391	0.987331081081
113	0.0228959576083	0.0206409961512	1.10924673599	0.996445664414
114	0.0226954520436	0.0280601371815	0.808814721639	0.993841497748
115	0.0229117398186	0.0395093599312	0.579906631199	0.987682995495
116	0.0274002899494	0.0323278328687	0.847575835371	0.986380912162
117	0.0336530670615	0.0207320942755	1.6232352899	0.993841497748
118	0.0218788801935	0.034337786034	0.637166303377	0.987331081081
119	0.0254088504029	0.0307253310069	0.826967507599	0.987331081081
120	0.0224546541398	0.0228473249433	0.982813270065	0.993841497748
121	0.0245675765354	0.0286833366524	0.856510413453	0.991237331081
122	0.0238238045334	0.0255257769018	0.933323386203	0.993841497748
123	0.0277336078919	0.0223226114933	1.2423997927	0.992539414414
124	0.0228621477121	0.0371710938925	0.615051786697	0.987331081081
125	0.0192043933453	0.0302456689791	0.634946886397	0.992539414414
126	0.0211140254174	0.0394031057095	0.535846731805	0.991237331081
127	0.022918921472	0.0386290826733	0.593307422436	0.987331081081
128	0.0191202691227	0.0265038730302	0.721414153353	0.989935247748
129	0.0244413824364	0.0241758860686	1.0109818671	0.991237331081
130	0.0176895511966	0.0339817265763	0.520560694786	0.981172578829
131	0.0222521185789	0.0220002635106	1.01144782053	0.991589245495
132	0.0192362676099	0.0240190195951	0.800876469324	0.987682995495
133	0.015584421479	0.0295083659933	0.528135698281	0.988633164414
134	0.0185637472801	0.0358655910689	0.517592118987	0.988633164414
135	0.0192383043332	0.0219842089066	0.875096502901	0.987682995495
136	0.0153746597007	0.0272167052472	0.564897902263	0.991237331081
137	0.0280715360663	0.0351650275755	0.798279938956	0.986028997748
138	0.0222937435917	0.0216930710846	1.02768960212	0.991237331081
139	0.0187935262037	0.0202159773125	0.929637282096	0.990639076577
140	0.0203503122665	0.0313944512132	0.64821366452	0.986028997748
141	0.0247071612729	0.0188031718681	1.31398901453	0.994193412162
142	0.0348143130238	0.0447938627509	0.777211673335	0.984726914414
143	0.0236851070055	0.0198548099584	1.19291532153	0.996445664414
144	0.02179658509	0.0208009513426	1.04786481787	0.990287162162
145	0.0146898958444	0.0213236306331	0.688902190117	0.987682995495
146	0.014700139809	0.0267951682516	0.54861158814	0.992539414414
147	0.0213425149842	0.0255957361733	0.833830870879	0.987682995495
148	0.0161619192199	0.0214469523029	0.7535764985	0.990639076577
149	0.0231830502428	0.0260970984264	0.888338230714	0.992539414414
150	0.0139022864666	0.027449253196	0.506472302448	0.991237331081
151	0.0200982434999	0.0256433640327	0.783760019718	0.990287162162
152	0.0155033325057	0.0243481187235	0.636736360691	0.991237331081
153	0.0174591873288	0.0183038318798	0.95385422263	0.992539414414
154	0.0171525071513	0.0161300766097	1.06338658931	0.996445664414
155	0.0184933335691	0.0221973593427	0.833132143495	0.987331081081
156	0.0152904053175	0.014552684333	1.05069312077	0.996445664414
157	0.014214618641	0.0169964611977	0.83632813182	0.990287162162
158	0.0185502551931	0.0152384385769	1.21733306857	0.992539414414
159	0.0141461067327	0.0177699229399	0.79607023511	0.993841497748
160	0.0150879927879	0.0256733310753	0.587691279469	0.988633164414
161	0.0159087432869	0.0226490582352	0.702401977233	0.992539414414
162	0.0171440574973	0.0308414785215	0.55587664143	0.990287162162
163	0.0168825132626	0.0311847817264	0.541370255876	0.987682995495
164	0.0158140508488	0.0200044407919	0.79052701414	0.991589245495
165	0.0189018723618	0.0201094716677	0.939948730333	0.992539414414
166	0.0220744998493	0.0293890979791	0.751111853277	0.986380912162
167	0.0155769093224	0.0145553882114	1.07018164656	0.993841497748
168	0.0145119177586	0.017774215578	0.816458970858	0.992539414414
169	0.0152436568528	0.0249581349394	0.610769069474	0.987682995495
170	0.0156920830629	0.0151056882769	1.03881946822	0.995143581081
171	0.0153742028407	0.0268233592636	0.573164706539	0.988985078829
172	0.0351256561832	0.0335160554115	1.04802476759	0.986028997748
173	0.0180940092132	0.0146718628608	1.23324552477	0.994193412162
174	0.0109696836939	0.0214462637643	0.511496259414	0.989935247748
175	0.018327653952	0.0201548708216	0.909341176841	0.996445664414
176	0.0135659463289	0.0184194014848	0.736503101913	0.992539414414
177	0.0118964418734	0.0195383381217	0.608876855302	0.992539414414
178	0.0166339498213	0.0208413061611	0.798124152713	0.990287162162
179	0.0197384850662	0.0174016159453	1.13429035144	0.994193412162
180	0.0123557389047	0.0177289733669	0.696923541425	0.995143581081
181	0.0153040349083	0.0336326897437	0.455034522216	0.985078828829
182	0.0166138565685	0.0236040851937	0.703855134914	0.991237331081
183	0.0119316163008	0.0158211004499	0.754158431555	0.993841497748
184	0.0164598220439	0.0579341897742	0.284112405957	0.980820664414
185	0.0217498953279	0.0298537497705	0.728548188923	0.987682995495
186	0.0146682793243	0.0352707919431	0.415876097932	0.986380912162
187	0.018065656886	0.0439566165021	0.41098834086	0.981172578829
188	0.01354029856	0.0345223876101	0.392217905463	0.986028997748
189	0.0149420052107	0.0230727242935	0.647604722382	0.986380912162
190	0.0178829357325	0.0234879391887	0.761366741835	0.990287162162
191	0.0119816893422	0.0239279861567	0.500739563446	0.989935247748
192	0.0123924138466	0.020742874148	0.597429929823	0.9921875
193	0.0134713205117	0.0674216147358	0.199807147373	0.976914414414
194	0.0204310435939	0.0188988095272	1.08107569234	0.989935247748
195	0.0152663163364	0.0277919235074	0.549307655238	0.989935247748
196	0.0202600110768	0.0265192710196	0.763973152271	0.9921875
197	0.0143487601794	0.022008894198	0.651952799185	0.989935247748
198	0.0201117922616	0.0268970580842	0.747732045588	0.987331081081
199	0.0191237202171	0.024383997724	0.784273376069	0.985078828829
200	0.0131494619229	0.019102482783	0.688364024317	0.993841497748
201	0.0117668806518	0.0146148026267	0.805134421062	0.993841497748
202	0.0174762704206	0.02872275497	0.608446872135	0.987331081081
203	0.0124522906098	0.0198376171671	0.627711005054	0.988633164414
204	0.0122861314439	0.0167262479508	0.734541989333	0.991237331081
205	0.0107015279391	0.0311463817398	0.343588158281	0.987331081081
206	0.0130561272177	0.0126231988993	1.0342962447	0.994193412162
207	0.00939151071048	0.0316886551385	0.296368232398	0.991237331081
208	0.0117386895995	0.0348142402639	0.337180691307	0.984726914414
209	0.0146328342693	0.0185462998402	0.788989415427	0.992539414414
210	0.0119573356143	0.0310427609882	0.38518917885	0.983776745495
211	0.0163717720415	0.0159488493765	1.02651744054	0.995143581081
212	0.00845856534752	0.0184895517802	0.457478117807	0.993841497748
213	0.0141459633173	0.0130897067585	1.08069367621	0.995495495495
214	0.00844437631052	0.0222188697988	0.380054268601	0.989336993243
215	0.00857166281091	0.019405915536	0.441703602957	0.993841497748
216	0.0160280430081	0.0428232530164	0.374283639824	0.982474662162
217	0.0164657848249	0.0179794986058	0.915808899122	0.993841497748
218	0.0139182927116	0.0170411384064	0.81674665035	0.996445664414
219	0.00976348050553	0.0243582683328	0.400828185819	0.995143581081
220	0.00981376201367	0.0171782169748	0.571291073343	0.993841497748
221	0.00882871712459	0.018500857191	0.477205841517	0.991589245495
222	0.00865328864691	0.0312644020272	0.276777679591	0.986028997748
223	0.0145276993358	0.017445708892	0.832737690724	0.991237331081
224	0.0181029947835	0.022555421418	0.802600600894	0.988633164414
225	0.0161278414354	0.020235912023	0.796991082833	0.98803490991
226	0.00799767515397	0.0198965938455	0.401962025063	0.990287162162
227	0.0111776633094	0.0122620439982	0.911566074218	0.995143581081
228	0.008022932719	0.0163696669944	0.490109708508	0.992539414414
229	0.00709600151525	0.0153562703162	0.462091469422	0.993841497748
230	0.0176067636025	0.0206378922048	0.853127995233	0.991237331081
231	0.0163606797654	0.0169162527877	0.967157441468	0.991589245495
232	0.0118062512577	0.0197614033886	0.597439919905	0.992891328829
233	0.00915101490428	0.0346399849135	0.264174910213	0.98412865991
234	0.0112425176429	0.0283573900176	0.396458123823	0.989935247748
235	0.0105601344244	0.0176389307082	0.598683366869	0.992539414414
236	0.0114224721859	0.0139985852704	0.815973326254	0.99609375
237	0.0115444325816	0.0150580362213	0.76666255891	0.991589245495
238	0.020042652029	0.0449250040573	0.446135786732	0.984726914414
239	0.0320542921271	0.0229857221743	1.39453056485	0.991237331081
240	0.0162755115883	0.0185848859454	0.875739115972	0.992539414414
241	0.0118060501345	0.0157901422321	0.747684850523	0.994791666667
242	0.0119790703341	0.0131980498427	0.907639422254	0.991589245495
243	0.00830655209447	0.0155742241699	0.533352544811	0.99609375
244	0.0178466874407	0.0226141701435	0.789181620524	0.991237331081
245	0.0204182011354	0.0316745861974	0.644624084688	0.983776745495
246	0.00954031342493	0.0165713425074	0.575711558713	0.991237331081
247	0.0216977257094	0.0151054436957	1.43641763503	0.99609375
248	0.0121736237924	0.0134570410854	0.904628566945	0.997395833333
249	0.00938185529661	0.0186863290635	0.50207053856	0.989935247748
250	0.00725813639094	0.022138150661	0.32785649091	0.992539414414


Confusion Matrix
[[669   2   0]
 [  0 151   4]
 [  0   3  63]]


Report
             precision    recall  f1-score   support

          0       1.00      1.00      1.00       671
          1       0.97      0.97      0.97       155
          2       0.94      0.95      0.95        66

avg / total       0.99      0.99      0.99       892
