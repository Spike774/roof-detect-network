printer: <experiment_settings.PrintLogSave instance at 0x7fd02b30f4d0>
data_augmentation: True
scaler: StandardScaler
display_mistakes: True
non_roofs: 2
test_percent: 0.2
net: MyNeuralNet(X_tensor_type=None,
      batch_iterator_test=<FlipBatchIterator.CropOnlyBatchIterator object at 0x7fd02b384dd0>,
      batch_iterator_train=<FlipBatchIterator.FlipBatchIterator object at 0x7fd02b384e10>,
      conv1_filter_size=(3, 3), conv1_num_filters=32,
      conv2_filter_size=(2, 2), conv2_num_filters=64,
      conv3_filter_size=(2, 2), conv3_num_filters=128, custom_score=None,
      eval_size=0.2, input_shape=(None, 3, 32, 32),
      layers=[('input', <class 'lasagne.layers.input.InputLayer'>), ('conv1', <class 'lasagne.layers.conv.Conv2DLayer'>), ('pool1', <class 'lasagne.layers.pool.MaxPool2DLayer'>), ('conv2', <class 'lasagne.layers.conv.Conv2DLayer'>), ('pool2', <class 'lasagne.layers.pool.MaxPool2DLayer'>), ('conv3', <class 'lasagne.layers.conv.Conv2DLayer'>), ('pool3', <class 'lasagne.layers.pool.MaxPool2DLayer'>), ('output', <class 'lasagne.layers.dense.DenseLayer'>)],
      loss=None, max_epochs=250, more_params={},
      net_name='conv3_nonroofs2_test20',
      objective=<class 'lasagne.objectives.Objective'>,
      objective_loss_function=<function categorical_crossentropy at 0x7fd045e568c0>,
      on_epoch_finished=[<experiment_settings.PrintLogSave instance at 0x7fd02b30f4d0>, <nolearn.lasagne.handlers.PrintLog instance at 0x7fd02b30f710>],
      on_training_finished=[],
      on_training_started=[<experiment_settings.SaveLayerInfo instance at 0x7fd02b30f680>, <nolearn.lasagne.handlers.PrintLayerInfo instance at 0x7fd02b30f758>],
      output_nonlinearity=<function softmax at 0x7fd0352a2938>,
      output_num_units=3, pool1_pool_size=(2, 2), pool2_pool_size=(2, 2),
      pool3_pool_size=(2, 2), preproc_scaler=None, regression=False,
      update=<function nesterov_momentum at 0x7fd03510c1b8>,
      update_learning_rate=0.01, update_momentum=0.9,
      use_label_encoder=False, verbose=1,
      y_tensor_type=TensorType(int32, vector))
preloaded: False

# Neural Network with 45507 learnable parameters
## Layer information

  #  name    size
---  ------  --------
  0  input   3x32x32
  1  conv1   32x30x30
  2  pool1   32x15x15
  3  conv2   64x14x14
  4  pool2   64x7x7
  5  conv3   128x6x6
  6  pool3   128x3x3
  7  output  3 

1	0.800488366778	0.665001504593	1.20373918141	0.7734375
2	0.602028497505	0.51567343308	1.16746075886	0.8125
3	0.463036101792	0.458567893341	1.00974383187	0.863541666667
4	0.359978651829	0.333220360701	1.0803020892	0.883854166667
5	0.297074550011	0.269409746894	1.10268671952	0.9109375
6	0.2515930081	0.246239108847	1.02174268449	0.91875
7	0.230754032885	0.237536303802	0.971447434318	0.925520833333
8	0.219226020374	0.233500118459	0.938868989964	0.9203125
9	0.199868520435	0.224900015269	0.888699452495	0.91875
10	0.173677898828	0.213882786973	0.812023731719	0.9203125
11	0.174439114084	0.180264814491	0.96768254291	0.933333333333
12	0.148555128991	0.169884231012	0.874449194643	0.928125
13	0.152791055669	0.169055935356	0.90378995181	0.939583333333
14	0.138508237215	0.144598346491	0.957882580099	0.957291666667
15	0.134668738852	0.157149027755	0.85694923332	0.941145833333
16	0.128965015183	0.13391864854	0.963010130318	0.954166666667
17	0.113071467754	0.126057030743	0.896986602711	0.955729166667
18	0.122045798867	0.124408050971	0.981012064045	0.958854166667
19	0.113587088468	0.115152218063	0.986408168065	0.955729166667
20	0.121730525706	0.122319342887	0.995186230021	0.955729166667
21	0.101093583272	0.123131826819	0.821019113283	0.950520833333
22	0.114731741406	0.123396889267	0.929778230939	0.958854166667
23	0.0939685178736	0.0995747657247	0.94369810654	0.963541666667
24	0.108081717419	0.09287786879	1.16369721686	0.961979166667
25	0.0966364289667	0.0948933104257	1.01836924577	0.965104166667
26	0.0902084119527	0.100045236377	0.901676233866	0.965104166667
27	0.0852353171346	0.101814230458	0.837165067702	0.963541666667
28	0.0892088017527	0.0890525334938	1.00175478735	0.969791666667
29	0.0850699477484	0.0949322404258	0.896112294062	0.965104166667
30	0.0813653209229	0.0781823224457	1.04071250863	0.969791666667
31	0.0958573037014	0.122912265956	0.779883951826	0.952083333333
32	0.0746879945207	0.0878853786824	0.849834132144	0.969791666667
33	0.0878028867715	0.0859569047846	1.02147566844	0.965104166667
34	0.0705483056633	0.0836485231526	0.843389733667	0.966666666667
35	0.080158172815	0.0750509268447	1.06805040504	0.968229166667
36	0.0690408511179	0.0706319693839	0.977473114798	0.972916666667
37	0.0661748876091	0.0668097829647	0.990496970242	0.971354166667
38	0.0667689536122	0.0678030287353	0.98474883582	0.974479166667
39	0.0734689040897	0.0692621700084	1.06073638872	0.968229166667
40	0.0689006383869	0.0571016638113	1.20663101192	0.9875
41	0.0690138768592	0.0601489208234	1.14738345949	0.976041666667
42	0.0645771926395	0.0564940450758	1.1430796388	0.984375
43	0.0704148640758	0.0792386597075	0.888642795521	0.969791666667
44	0.0667003396601	0.0594649162984	1.12167549897	0.984375
45	0.0606823724415	0.056038466811	1.08286996227	0.9859375
46	0.06485096484	0.069312188829	0.93563579416	0.9796875
47	0.0602911410864	0.0615983748946	0.978778112078	0.977604166667
48	0.0679241690293	0.0753569343854	0.901365874067	0.972916666667
49	0.0581161099194	0.0687119224501	0.845793682481	0.974479166667
50	0.0609308809444	0.0621847854375	0.979835831478	0.9796875
51	0.054971396411	0.0632635136203	0.868927336868	0.976041666667
52	0.066174884722	0.0533513859626	1.24035924331	0.9859375
53	0.0613312175114	0.0590340640259	1.03891233855	0.9828125
54	0.0672259898495	0.0581115989998	1.15684288518	0.979166666667
55	0.0570960081993	0.0580734185887	0.983169401541	0.984375
56	0.0840501797386	0.070045575341	1.19993560377	0.972916666667
57	0.0615941106658	0.0565959911214	1.08831225402	0.9828125
58	0.066919983062	0.0564418743758	1.1856442367	0.9828125
59	0.0545751751352	0.0582838921708	0.936368061612	0.98125
60	0.0598804606522	0.0609522564169	0.982415814808	0.9796875
61	0.0507815942022	0.0656864936237	0.773090347813	0.98125
62	0.0706429310268	0.0836174339384	0.84483495486	0.969791666667
63	0.0680465551667	0.0585841172585	1.16151882713	0.976041666667
64	0.0568325288743	0.0566929466484	1.00246207393	0.977604166667
65	0.0560278685189	0.0437104102145	1.28179690477	0.9875
66	0.0501669859455	0.0447884418485	1.12008776986	0.9859375
67	0.0580249581007	0.0521133333223	1.11343785557	0.9890625
68	0.0464089693583	0.0399141695943	1.16271915037	0.9890625
69	0.0512080921932	0.0495529828386	1.03340080172	0.9875
70	0.0454021781988	0.0451412644422	1.00577993904	0.9859375
71	0.0540983977053	0.104366762177	0.518348912784	0.961979166667
72	0.0553924733856	0.0456369186497	1.21376453592	0.990625
73	0.056448476599	0.0422558232807	1.33587449531	0.9875
74	0.0504880003984	0.0444593137153	1.1356000842	0.9890625
75	0.0473411393897	0.0516210024293	0.917090663912	0.9859375
76	0.0469876130781	0.0452258133409	1.03895562306	0.984375
77	0.0455389277497	0.0505504810273	0.900860423566	0.984375
78	0.050375895339	0.045866624715	1.0983126762	0.9859375
79	0.0519450215079	0.0558892507289	0.929427767064	0.98125
80	0.0499331555899	0.0422661288595	1.18139883962	0.9875
81	0.050269131729	0.0443894260841	1.1324573477	0.9875
82	0.0481187476924	0.0440498731385	1.09236972241	0.9875
83	0.0462726404964	0.0424588055284	1.08982435847	0.9875
84	0.0470543079692	0.040395348901	1.16484469746	0.9875
85	0.0345581224977	0.0428889978441	0.805757285897	0.9828125
86	0.045989073228	0.04140185299	1.11079746211	0.9859375
87	0.0468433591146	0.0628667336366	0.745121567559	0.9828125
88	0.0360363565496	0.0367792297612	0.979801827922	0.9875
89	0.0427857157924	0.0410490272883	1.04230766522	0.990625
90	0.046781128622	0.0529289915403	0.883846966674	0.9828125
91	0.0524127861524	0.066435681067	0.788925247858	0.9796875
92	0.04316471601	0.055807945592	0.77345108393	0.9859375
93	0.0410806483045	0.0419051877914	0.980323689491	0.9890625
94	0.0427278720391	0.0356817203949	1.197472307	0.9875
95	0.0432130922116	0.0411032444915	1.05133044231	0.9875
96	0.0399024205513	0.0568612912756	0.701750165291	0.974479166667
97	0.0300283906086	0.0525326882095	0.571613439785	0.977604166667
98	0.0500700342948	0.0550016094367	0.910337621164	0.9859375
99	0.0412872930869	0.0455639829219	0.90613880612	0.98125
100	0.0446062756711	0.0595158215482	0.74948601079	0.972916666667
101	0.0416695336621	0.049419198736	0.843185133063	0.977604166667
102	0.0396553431948	0.0381730460623	1.03883098902	0.9859375
103	0.0487072667611	0.0418174389724	1.16475967821	0.9890625
104	0.0483948220861	0.0365469747407	1.32418134276	0.9890625
105	0.0453781324581	0.0429302722	1.05701944415	0.984375
106	0.0480340187361	0.0519296902962	0.924981806404	0.984375
107	0.0448404260861	0.076862740283	0.583383131034	0.972916666667
108	0.0386180234582	0.0496326092527	0.778077639675	0.980729166667
109	0.0434267842327	0.0466377227667	0.931151472595	0.9859375
110	0.0397023617938	0.0405845119849	0.978263870922	0.9875
111	0.0398643509395	0.0438412225361	0.909289217623	0.9859375
112	0.0439278205568	0.0389675383895	1.12729267417	0.9859375
113	0.0410413621673	0.0650869457358	0.630562115081	0.9765625
114	0.0349252079156	0.0367264224304	0.950955895086	0.9890625
115	0.0433995300376	0.0396347972033	1.09498554553	0.990625
116	0.0474843613795	0.0638675488872	0.743481818339	0.9828125
117	0.0344583214281	0.0458168000818	0.752089219817	0.9859375
118	0.0371785775788	0.045056707079	0.825150793058	0.984375
119	0.0379975069628	0.0346213187529	1.09751760856	0.9890625
120	0.0302496387329	0.0380385572117	0.795236227404	0.9875
121	0.0411073505799	0.0345167413998	1.19093949524	0.9890625
122	0.0428551322396	0.0594707477605	0.720608599242	0.977604166667
123	0.0511137742317	0.0377092449444	1.3554706361	0.9890625
124	0.0386752019528	0.0393704378992	0.982341168057	0.9828125
125	0.0326115776724	0.040273057351	0.809761657482	0.984375
126	0.0306902467859	0.0392862880777	0.78119487199	0.9875
127	0.0309171094939	0.0384789749036	0.803480590929	0.990625
128	0.0365743639777	0.0345083148202	1.05987105335	0.9890625
129	0.0410684302401	0.0408485471938	1.00538288535	0.9890625
130	0.0304104409147	0.0439158520661	0.692470702128	0.984375
131	0.0394197696797	0.0314973267619	1.25152747018	0.990625
132	0.0356507108985	0.0465851917057	0.765279901041	0.9859375
133	0.0396534218208	0.0339860479182	1.1667558969	0.9921875
134	0.0357801404082	0.0372414373889	0.960761531155	0.9890625
135	0.0372120796914	0.061315849277	0.606891694891	0.974479166667
136	0.0333555819217	0.034429390763	0.968811273812	0.9890625
137	0.0405237167494	0.0535582268988	0.756629169707	0.971354166667
138	0.0363239168146	0.0387538302338	0.937298754612	0.984375
139	0.0345957163132	0.0366352487328	0.94432868644	0.9890625
140	0.0325810077401	0.0300702159958	1.08349762917	0.990625
141	0.0320582840532	0.0448302039884	0.715104576849	0.9828125
142	0.0306524060799	0.0369207479455	0.83022169879	0.984375
143	0.0284500469484	0.0770219887196	0.369375647414	0.969791666667
144	0.0380394594932	0.0448112293894	0.84888230052	0.9828125
145	0.035144844976	0.063962131271	0.549463319586	0.974479166667
146	0.0401300153418	0.0311394036851	1.28872138168	0.9890625
147	0.0341511613054	0.0518766264948	0.658314998738	0.979166666667
148	0.0448544202483	0.035784436136	1.25346170267	0.9875
149	0.0362812386931	0.0422501067518	0.858725373317	0.990625
150	0.0342943485265	0.0330628654077	1.03724671481	0.990625
151	0.0300352394274	0.0512052178964	0.58656599193	0.9875
152	0.0307974229319	0.0297693389179	1.03453499646	0.9890625
153	0.0358535437073	0.0333811354523	1.07406603225	0.9890625
154	0.0387577680286	0.0299954531347	1.29212143769	0.9890625
155	0.0308694869059	0.036047649092	0.856352291576	0.9890625
156	0.030242070749	0.0392102491841	0.771279738801	0.9828125
157	0.0241456510822	0.0410556299193	0.588120341343	0.9828125
158	0.0378820059651	0.0522483426859	0.725037465645	0.9828125
159	0.0314994440266	0.0418358257344	0.752929898565	0.9890625
160	0.0354373636941	0.0370629759465	0.956139187129	0.984375
161	0.036109915953	0.0394743231002	0.91476973174	0.984375
162	0.0343634994608	0.0386771142838	0.888471130723	0.9890625
163	0.0458322594766	0.024619904401	1.86159372231	0.9921875
164	0.0304470501493	0.0325457466159	0.935515491738	0.9890625
165	0.0270097113304	0.0409462489584	0.659638233476	0.98125
166	0.036079020321	0.0418524228499	0.86205332605	0.9875
167	0.0286422430394	0.0325246448951	0.880631998654	0.9828125
168	0.031429222487	0.0480080324965	0.654665914277	0.976041666667
169	0.0337653864651	0.0369158248777	0.914658864511	0.9859375
170	0.0317675890999	0.0325443032218	0.976133637997	0.9921875
171	0.0317611793036	0.0689950724344	0.460339821135	0.974479166667
172	0.0337273532251	0.0662626036155	0.508995291232	0.974479166667
173	0.0402381025596	0.0345997894815	1.16295801687	0.9859375
174	0.0294974694944	0.0288769389223	1.02148879332	0.990625
175	0.0254360822515	0.0322246261554	0.789336767753	0.9875
176	0.0254035440622	0.0302394740908	0.840078897731	0.990625
177	0.0328108961691	0.0323007307407	1.01579423799	0.990625
178	0.0270351420751	0.0391095897778	0.691266316745	0.98125
179	0.0266453842725	0.0346267875371	0.769502058024	0.9859375
180	0.0313900973871	0.0452199264035	0.694165158673	0.977604166667
181	0.0348077150572	0.026752241646	1.30111395964	0.990625
182	0.0324854898798	0.0321132244425	1.01159227838	0.9875
183	0.0310820031826	0.0274818441362	1.13100136325	0.990625
184	0.032750072982	0.0304129279508	1.07684709065	0.9921875
185	0.0285510327025	0.0362367085023	0.787903589551	0.990625
186	0.0377582828468	0.0312906585096	1.20669505358	0.990625
187	0.0251799588144	0.0303073021732	0.830821518539	0.9890625
188	0.0305713425481	0.0345823329567	0.88401619944	0.9890625
189	0.0216045762941	0.0273274903289	0.790580328967	0.9921875
190	0.033564147131	0.0322898196109	1.03946530316	0.9890625
191	0.0280936996714	0.0518443089365	0.541885893509	0.978125
192	0.029049856808	0.0454597076777	0.639024276486	0.9875
193	0.0330539521369	0.0442350462624	0.747234487805	0.974479166667
194	0.0436679695682	0.0351105942478	1.24372630266	0.982291666667
195	0.0353498013148	0.0362752404012	0.97448840928	0.977604166667
196	0.0327967543219	0.0365519040266	0.897265277838	0.990625
197	0.0347745618668	0.0608073484937	0.571880911241	0.972916666667
198	0.028631372405	0.0421433023755	0.679381320191	0.9859375
199	0.0315850416482	0.0346941659129	0.910384810158	0.9875
200	0.0284018549047	0.0462530725274	0.614053366679	0.974479166667
201	0.0366770206356	0.0299799302849	1.22338578799	0.9890625
202	0.03094938026	0.0310367307826	0.997185575914	0.9859375
203	0.0311751369908	0.0360471552287	0.864843197557	0.9859375
204	0.0254062629551	0.0303659062925	0.836670663155	0.990625
205	0.0293025490449	0.025656273142	1.14212024805	0.9890625
206	0.0274400944866	0.0540779304194	0.507417615167	0.9765625
207	0.0319639608969	0.0329043794865	0.971419652818	0.9859375
208	0.025073098933	0.0231284869273	1.08407865209	0.9921875
209	0.023526796873	0.0304770802647	0.771950484386	0.990625
210	0.0283817887856	0.0348557259883	0.814264743621	0.9859375
211	0.0281576484728	0.02710874484	1.03869244552	0.9953125
212	0.0265065383976	0.0260339477699	1.01815286071	0.9875
213	0.030715903128	0.0389830391241	0.78792992589	0.990625
214	0.0318842293069	0.0445996902745	0.714897998409	0.976041666667
215	0.0280189454213	0.0282306062493	0.992502434197	0.9921875
216	0.0342834135895	0.0455382335145	0.752849000578	0.98125
217	0.0308908270847	0.0307933748176	1.00316471539	0.9890625
218	0.0291187184124	0.0414040884417	0.703281234012	0.984375
219	0.0347041004208	0.0710768228763	0.488261841433	0.976041666667
220	0.0326524485183	0.0315341244202	1.03546393371	0.990625
221	0.0265277166012	0.0264277574098	1.00378235617	0.99375
222	0.0314299351561	0.031117933889	1.01002641333	0.9875
223	0.0283338218424	0.0484242942387	0.585115845008	0.972916666667
224	0.0291430742475	0.0358740499448	0.812372015213	0.990625
225	0.0291788902833	0.0212870219789	1.37073613737	0.9921875
226	0.0295463909905	0.0315208265516	0.937360920473	0.9890625
227	0.0278776164957	0.0416802139369	0.668845331214	0.982291666667
228	0.0345313920132	0.0334464532411	1.03243808138	0.990625
229	0.0284594868542	0.0293948327562	0.968179920949	0.9875
230	0.0297811832171	0.0390141664252	0.763342804573	0.979166666667
231	0.0238131063099	0.0338779592533	0.702908523262	0.9859375
232	0.027700184591	0.0248074039009	1.11660956953	0.9921875
233	0.0236404273131	0.0238011317752	0.993248032758	0.9921875
234	0.0294851450188	0.0260873422348	1.13024718093	0.990625
235	0.0262670065257	0.0310788268445	0.845173682297	0.9859375
236	0.0219585030555	0.0346275960411	0.634133048954	0.9828125
237	0.0215394573757	0.0269259279136	0.799952278146	0.990625
238	0.0234216177487	0.0257430098446	0.909824371358	0.990625
239	0.025534211758	0.0381585790517	0.669160445504	0.980729166667
240	0.0361648727748	0.0389203188994	0.929202889327	0.979166666667
241	0.0272447383582	0.0317244480924	0.858793138932	0.9875
242	0.0205905785564	0.0278892912781	0.73829694527	0.990625
243	0.0232205120925	0.0272106542411	0.853361035966	0.9890625
244	0.0195256074725	0.0361442946321	0.540212713271	0.9875
245	0.0304531484453	0.0519419739005	0.586291705118	0.98125
246	0.0263582738115	0.0311524052262	0.846107182417	0.990625
247	0.0275692208325	0.0270534759198	1.01906390566	0.9890625
248	0.0237089712942	0.0347344760411	0.682577484863	0.984375
249	0.0237029758675	0.0281183354245	0.842972228249	0.990625
250	0.0219793856447	0.0256287491317	0.857606648369	0.9921875


Confusion Matrix
[[464   0   0]
 [  0 142   3]
 [  0   7  53]]


Report
             precision    recall  f1-score   support

          0       1.00      1.00      1.00       464
          1       0.95      0.98      0.97       145
          2       0.95      0.88      0.91        60

avg / total       0.99      0.99      0.98       669
