printer: <experiment_settings.PrintLogSave instance at 0x7fe8a3ff49e0>
roofs_only: True
data_augmentation: True
scaler: StandardScaler
display_mistakes: True
non_roofs: 1
test_percent: 0.2
net: MyNeuralNet(X_tensor_type=None,
      batch_iterator_test=<FlipBatchIterator.CropOnlyBatchIterator object at 0x7fe8a406ddd0>,
      batch_iterator_train=<FlipBatchIterator.FlipBatchIterator object at 0x7fe8a406de10>,
      custom_score=None, eval_size=0.2, input_shape=(None, 3, 32, 32),
      layers=[('input', <class 'lasagne.layers.input.InputLayer'>), ('conv1', <class 'lasagne.layers.conv.Conv2DLayer'>), ('pool1', <class 'lasagne.layers.pool.MaxPool2DLayer'>), ('conv2', <class 'lasagne.layers.conv.Conv2DLayer'>), ('pool2', <class 'lasagne.layers.pool.MaxPool2DLayer'>), ('output', <class 'lasagne.layers.dense.DenseLayer'>)],
      loss=None, max_epochs=250, more_params={},
      net_name='conv2_nonroofs1_test20_roofs',
      objective=<class 'lasagne.objectives.Objective'>,
      objective_loss_function=<function categorical_crossentropy at 0x7fe8beb428c0>,
      on_epoch_finished=[<experiment_settings.PrintLogSave instance at 0x7fe8a3ff49e0>, <nolearn.lasagne.handlers.PrintLog instance at 0x7fe8a3ff4c20>],
      on_training_finished=[],
      on_training_started=[<experiment_settings.SaveLayerInfo instance at 0x7fe8a3ff4b48>, <nolearn.lasagne.handlers.PrintLayerInfo instance at 0x7fe8a3ff4c68>],
      output_nonlinearity=<function softmax at 0x7fe8adf4c938>,
      output_num_units=3, preproc_scaler=None, regression=False,
      update=<function nesterov_momentum at 0x7fe8add761b8>,
      update_learning_rate=0.01, update_momentum=0.9,
      use_label_encoder=False, verbose=1,
      y_tensor_type=TensorType(int32, vector))
plot_loss: True
preloaded: False

# Neural Network with 18563 learnable parameters
## Layer information

  #  name    size
---  ------  --------
  0  input   3x32x32
  1  conv1   32x30x30
  2  pool1   32x15x15
  3  conv2   64x14x14
  4  pool2   64x7x7
  5  output  3 

1	0.810858354299	0.568812767195	1.42552769745	0.77453125
2	0.530361330467	0.439912572499	1.20560621274	0.8240625
3	0.426527641942	0.433064913476	0.984904638241	0.81015625
4	0.373608051091	0.443678098841	0.842070077532	0.81625
5	0.357069582329	0.440414552715	0.810757910081	0.800625
6	0.335368743315	0.391534109264	0.856550515984	0.85015625
7	0.322047664828	0.376624711315	0.855089045282	0.861875
