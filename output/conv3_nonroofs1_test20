printer: <experiment_settings.PrintLogSave instance at 0x7f3062a214d0>
data_augmentation: True
scaler: StandardScaler
display_mistakes: True
non_roofs: 1
test_percent: 0.2
net: MyNeuralNet(X_tensor_type=None,
      batch_iterator_test=<FlipBatchIterator.CropOnlyBatchIterator object at 0x7f3062a96dd0>,
      batch_iterator_train=<FlipBatchIterator.FlipBatchIterator object at 0x7f3062a96e10>,
      conv1_filter_size=(3, 3), conv1_num_filters=32,
      conv2_filter_size=(2, 2), conv2_num_filters=64,
      conv3_filter_size=(2, 2), conv3_num_filters=128, custom_score=None,
      eval_size=0.2, input_shape=(None, 3, 32, 32),
      layers=[('input', <class 'lasagne.layers.input.InputLayer'>), ('conv1', <class 'lasagne.layers.conv.Conv2DLayer'>), ('pool1', <class 'lasagne.layers.pool.MaxPool2DLayer'>), ('conv2', <class 'lasagne.layers.conv.Conv2DLayer'>), ('pool2', <class 'lasagne.layers.pool.MaxPool2DLayer'>), ('conv3', <class 'lasagne.layers.conv.Conv2DLayer'>), ('pool3', <class 'lasagne.layers.pool.MaxPool2DLayer'>), ('output', <class 'lasagne.layers.dense.DenseLayer'>)],
      loss=None, max_epochs=250, more_params={},
      net_name='conv3_nonroofs1_test20',
      objective=<class 'lasagne.objectives.Objective'>,
      objective_loss_function=<function categorical_crossentropy at 0x7f307d5688c0>,
      on_epoch_finished=[<experiment_settings.PrintLogSave instance at 0x7f3062a214d0>, <nolearn.lasagne.handlers.PrintLog instance at 0x7f3062a21710>],
      on_training_finished=[],
      on_training_started=[<experiment_settings.SaveLayerInfo instance at 0x7f3062a21680>, <nolearn.lasagne.handlers.PrintLayerInfo instance at 0x7f3062a21758>],
      output_nonlinearity=<function softmax at 0x7f306c9b4938>,
      output_num_units=3, pool1_pool_size=(2, 2), pool2_pool_size=(2, 2),
      pool3_pool_size=(2, 2), preproc_scaler=None, regression=False,
      update=<function nesterov_momentum at 0x7f306c81e1b8>,
      update_learning_rate=0.01, update_momentum=0.9,
      use_label_encoder=False, verbose=1,
      y_tensor_type=TensorType(int32, vector))
preloaded: False

# Neural Network with 45507 learnable parameters
## Layer information

  #  name    size
---  ------  --------
  0  input   3x32x32
  1  conv1   32x30x30
  2  pool1   32x15x15
  3  conv2   64x14x14
  4  pool2   64x7x7
  5  conv3   128x6x6
  6  pool3   128x3x3
  7  output  3 

1	0.852231303983	0.720320943485	1.18312720419	0.741800742574
2	0.66706201026	0.577000797342	1.15608507533	0.814382219472
3	0.512292692198	0.41414521922	1.23698806221	0.874458539604
4	0.392613103815	0.330392679231	1.18832264906	0.88105919967
5	0.326056873288	0.28222063925	1.15532610993	0.903981023102
6	0.2870798772	0.236095717504	1.21594699063	0.911793523102
7	0.254263707162	0.205358083228	1.23814803472	0.917698019802
8	0.223943877568	0.191711704154	1.16812835479	0.926206683168
9	0.199376999542	0.178791636667	1.11513605031	0.928810849835
10	0.186085973837	0.163188576491	1.14031250127	0.928810849835
11	0.182488779433	0.164848998936	1.10700568769	0.934019183168
12	0.161452839283	0.161958249293	0.996879380871	0.934019183168
13	0.16591994685	0.144656307767	1.14699420586	0.939227516502
14	0.153894707713	0.136907055416	1.12408164243	0.944435849835
15	0.157288019765	0.127076841575	1.23773944815	0.945132013201
16	0.152841410576	0.128881533603	1.18590620629	0.947040016502
17	0.143841337194	0.112811778263	1.27505602171	0.944435849835
18	0.141624148674	0.1200092957	1.18010982272	0.950340346535
19	0.134636267552	0.153521598698	0.876985835833	0.943224009901
20	0.133474749043	0.108276922126	1.23271650525	0.952944513201
21	0.133924720985	0.141848256119	0.944140764567	0.951036509901
22	0.121849572492	0.117767548639	1.0346617035	0.952944513201
23	0.127480800402	0.0936518800391	1.36121987459	0.954852516502
24	0.12509394455	0.107258782206	1.16628160396	0.950340346535
25	0.112789722151	0.109611343045	1.02899680833	0.947040016502
26	0.119981524313	0.119380220656	1.00503687842	0.942527846535
27	0.126555166059	0.113978982149	1.11033774537	0.947736179868
28	0.112797590615	0.121975114019	0.924759050418	0.952944513201
29	0.114247655022	0.0902109387171	1.26645012952	0.961453176568
30	0.114493598367	0.0890844320897	1.28522566381	0.958152846535
31	0.115239292255	0.0883516463805	1.30432535189	0.958152846535
32	0.097816784845	0.0863171751639	1.13322504657	0.960757013201
33	0.104956402443	0.0948262777298	1.10682824377	0.950340346535
34	0.101730731799	0.070061983422	1.45201044604	0.963361179868
35	0.102204769542	0.113850693455	0.897708801237	0.953640676568
36	0.103694281102	0.0663134783518	1.56369841666	0.968569513201
37	0.097489707526	0.0820309506282	1.18845029564	0.957456683168
38	0.121020022521	0.0832791449162	1.45318521993	0.955548679868
39	0.0957181396462	0.0660593493994	1.44897187932	0.971173679868
40	0.0995401900871	0.0797423525205	1.24827255456	0.963361179868
41	0.0979729658645	0.0586094674408	1.67162354723	0.978986179868
42	0.088174445168	0.057849562113	1.52420246493	0.976382013201
43	0.103266489399	0.0541919084952	1.90557026438	0.980378506601
44	0.0883346264812	0.0650884098985	1.35714832516	0.973777846535
45	0.0863073758904	0.0605365645598	1.42570653815	0.971173679868
46	0.0809561565198	0.0556415985081	1.45495741838	0.977078176568
47	0.0845279492406	0.0565237532461	1.49544119748	0.979682343234
48	0.0827832889751	0.0593387339156	1.3950969883	0.973777846535
49	0.0738743818137	0.0700517389155	1.05456885093	0.977078176568
50	0.0827942511366	0.0569297223981	1.45432381626	0.979682343234
51	0.079357216315	0.055623578712	1.42668303897	0.980378506601
52	0.0700747115977	0.0519452297463	1.34901148652	0.982286509901
53	0.0770402617279	0.0592885707825	1.29941168612	0.982286509901
54	0.0855691722254	0.054931222101	1.55775111044	0.979682343234
55	0.0717528660995	0.0551038507434	1.3021388729	0.985586839934
56	0.0732799346993	0.0548217916734	1.33669353851	0.979682343234
57	0.0769003351841	0.04389359079	1.75197184373	0.985586839934
58	0.0716919772054	0.0415519510226	1.72535766531	0.984890676568
59	0.0767167897773	0.0708363758417	1.0830140428	0.964057343234
60	0.0752555798601	0.0529189555252	1.42209117911	0.977078176568
61	0.0678552284981	0.0455212863411	1.49062634104	0.988191006601
62	0.0686225942113	0.0593544712109	1.15614869127	0.971869843234
63	0.080102487738	0.0350581973089	2.28484331445	0.991491336634
64	0.063041617915	0.0479076979424	1.31589745746	0.988191006601
65	0.0729175941936	0.0384487976507	1.89648568093	0.991491336634
66	0.0614785498225	0.0387064918007	1.58832658199	0.988887169967
67	0.082465768862	0.0482062244736	1.71068715218	0.9862830033
68	0.0653628952762	0.0425067305704	1.53770695603	0.988191006601
69	0.0743406167846	0.0354971149781	2.09427207903	0.994791666667
70	0.0640441886737	0.0456730361438	1.40223190926	0.979682343234
71	0.0529012558101	0.0351196013195	1.50631709423	0.9921875
72	0.056115291871	0.0323534549996	1.73444511171	0.994791666667
73	0.0656214780803	0.040580443641	1.61707148056	0.982286509901
74	0.0662331318922	0.0414917978633	1.59629457635	0.991491336634
75	0.0700922933678	0.0458959197415	1.52720097478	0.982286509901
76	0.0673272086486	0.0361078540155	1.8646139596	0.9921875
77	0.0651930657783	0.0400462729563	1.62794340061	0.9862830033
78	0.0694118745851	0.0397180704698	1.74761446778	0.988887169967
79	0.0604357598853	0.044657266537	1.3533242084	0.977774339934
80	0.0680393869076	0.0354148515893	1.92121056151	0.994791666667
81	0.0613656953732	0.0444112019926	1.38176164165	0.9862830033
82	0.0583546247664	0.0518775806565	1.12485247052	0.971869843234
83	0.068854249482	0.0325611801605	2.11461160629	0.991491336634
84	0.0617070839666	0.0436327949185	1.41423633489	0.979682343234
85	0.0603760010131	0.0386449681697	1.56232502892	0.982982673267
86	0.05356892402	0.0383478559875	1.39692096574	0.979682343234
87	0.0504846617676	0.0465612860725	1.08426261442	0.979682343234
88	0.0586009662366	0.0415234338873	1.41127456837	0.979682343234
89	0.0551804647849	0.0347511741808	1.58787339092	0.982982673267
90	0.0570425172934	0.0425467815991	1.34070110945	0.982982673267
91	0.0604472007204	0.0628834272565	0.96125805093	0.969265676568
92	0.0682694636754	0.051992067349	1.31307461227	0.982286509901
93	0.0604228848479	0.0390400072792	1.54771704871	0.985586839934
94	0.0654427306807	0.0402404177445	1.62629352151	0.985586839934
95	0.0613020599483	0.0308920245863	1.98439761619	0.9862830033
96	0.0521758802292	0.031764352083	1.64259230262	0.9862830033
97	0.0568876422871	0.0325690824396	1.74667623482	0.982982673267
98	0.0521028836102	0.0322701024587	1.61458686649	0.9862830033
99	0.0481624449346	0.0313480007059	1.53638011516	0.989583333333
100	0.0504507448366	0.0400309336165	1.26029398464	0.980378506601
101	0.0595831143376	0.035958362984	1.65700297214	0.985586839934
102	0.0584472406593	0.0330103499145	1.77057319328	0.9862830033
103	0.0503333176567	0.0441175308733	1.14089153813	0.979682343234
104	0.0477239317989	0.0439212174839	1.08658034847	0.988887169967
105	0.0497610119508	0.0307882944102	1.61623152253	0.9862830033
106	0.0562782028829	0.0321433971044	1.75084801087	0.988887169967
107	0.0518341565074	0.0298393327338	1.73710843234	0.9921875
108	0.0467590556868	0.0295164722835	1.58416816338	0.994791666667
109	0.0500106881877	0.0385914993026	1.29589907341	0.9862830033
110	0.0587167518145	0.0370027028868	1.58682331921	0.982982673267
111	0.0543154874177	0.0520596260205	1.04333226282	0.977774339934
112	0.0486836370886	0.0448531030479	1.08540176221	0.972566006601
113	0.0482165529942	0.0398698416233	1.20934899742	0.977774339934
114	0.0474330247497	0.0323615034023	1.46572376938	0.983678836634
115	0.045134132002	0.0348275465844	1.29593199718	0.982982673267
116	0.0595756580284	0.0412632724238	1.44379382751	0.983678836634
117	0.0389053690144	0.0300711529676	1.29377709782	0.9862830033
118	0.0438013478735	0.0355228054285	1.23304866677	0.980378506601
119	0.0529860146922	0.0344469319952	1.53819256529	0.985586839934
120	0.0395391850318	0.0310124115849	1.27494712637	0.982982673267
121	0.0459626377356	0.0349514847131	1.31504106658	0.983678836634
122	0.0457750693958	0.0419107146702	1.09220445788	0.983678836634
123	0.0497588593843	0.0482460795114	1.03135549848	0.979682343234
124	0.0528768465491	0.0379750638229	1.3924096822	0.982982673267
125	0.0489429944298	0.0318145621655	1.53838340365	0.985586839934
126	0.0437491531611	0.0345250931585	1.26716973537	0.985586839934
127	0.0399822411664	0.0515849725175	0.775075360423	0.980378506601
128	0.0449319538881	0.029363034109	1.53022176528	0.989583333333
129	0.0404875332037	0.0320608539987	1.26283389723	0.985586839934
130	0.0463574850097	0.0439742589	1.05419593574	0.982982673267
131	0.0463087840658	0.0273918470179	1.69060465457	0.991491336634
132	0.0458402240456	0.0327855779453	1.39818258266	0.982982673267
133	0.0532669476809	0.0374397535311	1.42273766938	0.985586839934
134	0.0355612868274	0.0268402642266	1.3249231277	0.988887169967
135	0.0405684546507	0.0357358982936	1.13522974342	0.982982673267
136	0.0437519376996	0.0339189295508	1.28989736053	0.9862830033
137	0.0444171720229	0.0281651959416	1.57702336299	0.9862830033
138	0.0409642313936	0.029982589834	1.36626727779	0.985586839934
139	0.0418716051652	0.0385113039398	1.08725493249	0.9862830033
140	0.0338432811415	0.0415996175918	0.813547890598	0.980378506601
141	0.0447835346921	0.0312410566883	1.43348335298	0.985586839934
142	0.0487979446663	0.0317620816839	1.53635851554	0.982982673267
143	0.0368337831934	0.0344167043757	1.07022981606	0.988887169967
144	0.0519096529502	0.0469720886338	1.10511698458	0.980378506601
145	0.0458636586303	0.0331652280451	1.38288386161	0.9862830033
146	0.0455891458557	0.0360747799513	1.26374009536	0.988191006601
147	0.0361377462051	0.0375336691364	0.962808780397	0.981074669967
148	0.0438630504343	0.0338570733839	1.29553579357	0.982982673267
149	0.0407927249403	0.0307166514193	1.32803294159	0.982982673267
150	0.0455026015171	0.0376208804147	1.20950389825	0.985586839934
151	0.0390557899294	0.0340565177691	1.14679340366	0.9862830033
152	0.0395270411599	0.0301002411834	1.31318021404	0.983678836634
153	0.043221735603	0.0399411203225	1.08213628596	0.983678836634
154	0.0501669580538	0.0366291245487	1.36959205746	0.982982673267
155	0.0445414598918	0.0319356707767	1.3947244197	0.9862830033
156	0.0430337405079	0.0257831561275	1.66906410895	0.994791666667
157	0.0485234522252	0.0311101801589	1.55972906545	0.9862830033
158	0.0428303248809	0.0315223140969	1.35873035048	0.983678836634
159	0.0532339884874	0.0333812921499	1.59472522059	0.983678836634
160	0.0470981185484	0.0305849826383	1.53990993245	0.985586839934
161	0.0394606480773	0.0300447432996	1.3133960801	0.988191006601
162	0.0291282524392	0.0252316298988	1.15443403998	0.9862830033
163	0.0367045034903	0.0312879904509	1.17311795872	0.982982673267
164	0.037108535451	0.033070627372	1.12209953061	0.988887169967
165	0.0438326480747	0.0290695876967	1.50785241717	0.9862830033
166	0.0560890716249	0.0264441148471	2.12104174971	0.988887169967
167	0.0437496113517	0.0297575110826	1.47020398414	0.985586839934
168	0.0381839880483	0.0276070960068	1.38312222477	0.994791666667
169	0.0326851542698	0.0309598735828	1.05572634793	0.985586839934
170	0.0301043180735	0.0333767716633	0.901954160731	0.9862830033
171	0.0373112256182	0.0302790284736	1.23224645899	0.988887169967
172	0.0448440713331	0.0351072427208	1.27734529566	0.980378506601
173	0.0371798932032	0.0308580727047	1.20486763898	0.989583333333
174	0.038838308635	0.0329869000228	1.17738582917	0.982982673267
175	0.0418946743503	0.0260806287014	1.6063521639	0.9862830033
176	0.0394332740014	0.0369607331216	1.06689642415	0.983678836634
177	0.0407353295615	0.0407138808049	1.0005268168	0.977078176568
178	0.0421079310297	0.0556746886484	0.756320907255	0.966661509901
179	0.0434218615487	0.0329530965009	1.31768683855	0.985586839934
180	0.0344652203943	0.0376101138655	0.916381708323	0.980378506601
181	0.0362286276243	0.0308699463049	1.17358894203	0.984375
182	0.0337849028452	0.0314192453443	1.07529326294	0.980378506601
183	0.0283753483914	0.0297003372267	0.955388087847	0.985586839934
184	0.0312073150052	0.0474962444349	0.657048054567	0.9862830033
185	0.0369066574417	0.0240582455656	1.53405439898	0.9921875
186	0.0436729361425	0.0329981504994	1.32349648334	0.988887169967
187	0.0426408801552	0.0765196148111	0.557254244686	0.971869843234
188	0.0402506555484	0.0310137023432	1.29783458624	0.9940955033
189	0.0383813064213	0.027549783499	1.39316181641	0.989583333333
190	0.0356236518651	0.0415768860571	0.856813851238	0.977774339934
191	0.041065471312	0.0246332206172	1.66707682889	0.9921875
192	0.0316071675984	0.0313973570972	1.00668242555	0.983678836634
193	0.0335998689939	0.0323793793677	1.03769342248	0.985586839934
194	0.0313857926987	0.0381649169925	0.822372879913	0.982982673267
195	0.0367035669312	0.0299236677544	1.22657313376	0.988887169967
196	0.0244431159814	0.0346058840731	0.706328320634	0.980378506601
197	0.0313690494185	0.0298652445058	1.05035300858	0.983678836634
198	0.0336169905479	0.0363715410992	0.924266322842	0.9862830033
199	0.0461976644253	0.037066331473	1.24635113834	0.9862830033
200	0.0347214142879	0.0258527267998	1.3430465017	0.989583333333
201	0.0338833135036	0.0278540096249	1.21646089593	0.985586839934
202	0.0323726182083	0.0325110492264	0.995742031666	0.9862830033
203	0.0290594272105	0.0268295203856	1.08311392797	0.988887169967
204	0.0345309596366	0.025344613775	1.36245752029	0.9921875
205	0.0308083031017	0.025792791191	1.19445401909	0.9862830033
206	0.032571704527	0.0255287667005	1.27588241568	0.988887169967
207	0.0278824382859	0.0299114282332	0.932166731341	0.985586839934
208	0.0447082710299	0.0276461972708	1.61715807031	0.989583333333
209	0.0348718741005	0.0261900476068	1.33149334526	0.991491336634
210	0.0362301324685	0.027469695209	1.31891279437	0.985586839934
211	0.0378759083533	0.0334695295296	1.13165344376	0.982286509901
212	0.0287469486926	0.0298243854472	0.963873966271	0.991491336634
213	0.0330353905008	0.0250010891651	1.32135805295	0.9862830033
214	0.0345937524401	0.0333250624965	1.03807014447	0.988887169967
215	0.0339896817954	0.0302480682602	1.12369760287	0.9862830033
216	0.0328837427455	0.034424411679	0.95524487251	0.9862830033
217	0.03535757581	0.037430737024	0.94461340121	0.982982673267
218	0.0419599889482	0.0224969192901	1.865143774	0.994791666667
219	0.0301449354972	0.0246651416339	1.22216754092	0.9862830033
220	0.0302770961098	0.0297888416725	1.01639051436	0.980378506601
221	0.0340862937245	0.0234619017486	1.4528359248	0.988887169967
222	0.0303029412322	0.0211677825009	1.43155955192	0.988887169967
223	0.0232666476816	0.0212796820791	1.09337383872	0.9921875
224	0.0333580971347	0.0237881974732	1.40229612489	0.988887169967
225	0.0318609709422	0.0245204375896	1.29936388067	0.9862830033
226	0.0337035427166	0.0259139584576	1.30059414781	0.988887169967
227	0.0384351513019	0.0338433987376	1.13567646086	0.988887169967
228	0.0356291193722	0.0386339924515	0.922222041042	0.982286509901
229	0.0314765621985	0.0402321558709	0.782373241431	0.9940955033
230	0.0325050355887	0.0235710842116	1.37902165623	0.9921875
231	0.0328986423197	0.0297317995426	1.10651365964	0.988887169967
232	0.0280105319107	0.0251268128226	1.11476660842	0.9862830033
233	0.0273990856566	0.0230241798591	1.19001353465	0.9921875
234	0.0276199420006	0.0319349233466	0.864882050941	0.983678836634
235	0.0271818286729	0.023206242433	1.17131537997	0.9921875
236	0.0303288103131	0.0270190750939	1.12249624414	0.988887169967
237	0.0266188137701	0.0242747655467	1.09656316634	0.991491336634
238	0.032478271055	0.0348906758871	0.930858179993	0.9940955033
239	0.0353841314209	0.0260161336009	1.36008416791	0.989583333333
240	0.0256977644429	0.0255992973198	1.00384647758	0.9921875
241	0.0336775895428	0.0344961180625	0.976271865773	0.985586839934
242	0.0292486858764	0.0278018995278	1.05203911866	0.988887169967
243	0.0357157099475	0.0297589657833	1.20016637028	0.988191006601
244	0.0333395623749	0.0246118692668	1.35461317519	0.994791666667
245	0.0289840283007	0.0241511627789	1.20010902026	0.9940955033
246	0.0321878461654	0.0295690473619	1.0885655453	0.985586839934
247	0.0367257294727	0.024633380755	1.4908927783	0.994791666667
248	0.0306957206028	0.0398435128612	0.770406984691	0.981074669967
249	0.0352347059771	0.0257370921508	1.36902435484	0.988887169967
250	0.0257139251906	0.0260427388956	0.987374073583	0.9862830033


Confusion Matrix
[[213   0   0]
 [  2 157   2]
 [  0   5  67]]


Report
             precision    recall  f1-score   support

          0       0.99      1.00      1.00       213
          1       0.97      0.98      0.97       161
          2       0.97      0.93      0.95        72

avg / total       0.98      0.98      0.98       446
